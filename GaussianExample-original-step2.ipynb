{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GaussianExample with original step2 method\n",
    "\n",
    "In the original version of the GaussianExample, step2 is implemented in a simpler way than in the papers.  Instead of updating the weights in each iteration of step2, it always uses weight=1 for the gen-level sample in the compaison.\n",
    "\n",
    "In the original OmniFold paper, they propose instead updating the weights of the previous iteration, rather than always starting from the beginning (weight=1).  I'll try to implement the original version here.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-17T03:48:59.924067Z",
     "start_time": "2020-11-17T03:48:57.190005Z"
    }
   },
   "outputs": [],
   "source": [
    "from __future__ import absolute_import, division, print_function\n",
    "\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "from tensorflow.keras.layers import Dense, Input\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "\n",
    "import matplotlib as mpl\n",
    "mpl.rcParams.update(mpl.rcParamsDefault)\n",
    "mpl.rcParams[\"text.usetex\"]=False "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "#from IPython.core.display import display, HTML\n",
    "#display(HTML(\"<style>.container { width:100% !important; }</style>\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU'), PhysicalDevice(name='/physical_device:GPU:1', device_type='GPU')]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-01-26 20:12:55.063593: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-01-26 20:12:55.063820: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-01-26 20:12:55.080156: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-01-26 20:12:55.080397: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-01-26 20:12:55.080569: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-01-26 20:12:55.080733: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n"
     ]
    }
   ],
   "source": [
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "print(gpus)\n",
    "tf.config.experimental.set_virtual_device_configuration(gpus[0], [tf.config.experimental.VirtualDeviceConfiguration(memory_limit=1024)]) #in MB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define default plot styles  \n",
    "\n",
    "from matplotlib import rc\n",
    "import matplotlib.font_manager\n",
    "\n",
    "rc('font', family='serif')\n",
    "rc('text', usetex=False)\n",
    "rc('font', size=22)\n",
    "rc('xtick', labelsize=15)\n",
    "rc('ytick', labelsize=15)\n",
    "rc('legend', fontsize=15)\n",
    "\n",
    "plot_style_0 = {\n",
    "    'histtype': 'step',\n",
    "    'color': 'black',\n",
    "    'linewidth': 2,\n",
    "    'linestyle': '--',\n",
    "    'density': False\n",
    "}\n",
    "\n",
    "plot_style_1 = {\n",
    "    'histtype': 'step',\n",
    "    'color': 'black',\n",
    "    'linewidth': 2,\n",
    "    'density': False\n",
    "}\n",
    "\n",
    "plot_style_2 = {'alpha': 0.5, 'density': False}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-17T03:48:59.971307Z",
     "start_time": "2020-11-17T03:48:59.954584Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.11.0\n"
     ]
    }
   ],
   "source": [
    "# Check Versions\n",
    "import tensorflow as tf\n",
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# OmniFold Gaussian Toy Example"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup the Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-17T03:48:59.978107Z",
     "start_time": "2020-11-17T03:48:59.974831Z"
    }
   },
   "outputs": [],
   "source": [
    "mu0 = 0\n",
    "sigma0 = 1\n",
    "\n",
    "eff = 0.1 #fraction of true but not reco\n",
    "fake = 0.1 #fraction of reco but not true\n",
    "\n",
    "\n",
    "##-- original value\n",
    "#back = 0.1 #fraction of a background process that we would like to subtract\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Owen: learning hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "##-- originals\n",
    "\n",
    "max_epochs = 200\n",
    "batch_size_setval = 10000\n",
    "learning_rate_setval = 1e-3\n",
    "patience_setval = 10\n",
    "\n",
    "back = 0.1 #fraction of a background process that we would like to subtract\n",
    "background_param = (0, 1.2)  # background\n",
    "N = 10**5\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "##-- alt1\n",
    "##-- more thorough set with more events, higher background, wider background width \n",
    "##  3 min + 50 min\n",
    "\n",
    "#max_epochs = 200\n",
    "#batch_size_setval = 1000\n",
    "#learning_rate_setval = 1e-4\n",
    "#patience_setval = 40\n",
    "\n",
    "#back = 0.2 #fraction of a background process that we would like to subtract\n",
    "#background_param = (0, 3)  # background\n",
    "#N = 3*10**5\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "##-- alt2\n",
    "##-- more thorough set with a lot more events, higher background, wider background width \n",
    "##   About 3 hours.\n",
    "\n",
    "#max_epochs = 200\n",
    "#batch_size_setval = 1000\n",
    "#learning_rate_setval = 1e-4\n",
    "#patience_setval = 40\n",
    "\n",
    "#back = 0.2 #fraction of a background process that we would like to subtract\n",
    "#background_param = (0, 3)  # background\n",
    "#N = 10**6\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "##-- alt5\n",
    "##   similar to alt4 but with sample size of 1M.\n",
    "##-- more thorough set with more events, higher background, wider background width \n",
    "##  about 30 min\n",
    "\n",
    "max_epochs = 200\n",
    "batch_size_setval = 16384\n",
    "learning_rate_setval = 1e-4\n",
    "patience_setval = 40\n",
    "\n",
    "back = 0.2 #fraction of a background process that we would like to subtract\n",
    "background_param = (0, 3)  # background\n",
    "N = 10**6\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-17T03:49:24.308730Z",
     "start_time": "2020-11-17T03:48:59.981078Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 4.91 s, sys: 56.6 ms, total: 4.97 s\n",
      "Wall time: 4.97 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "#N = 10**5\n",
    "\n",
    "\n",
    "# param = (mu, sigma)\n",
    "theta0_param = (mu0, sigma0)  # synthetic sample\n",
    "theta_unknown_param = (0.2, 0.8)  # this is the data (the target)\n",
    "#background_param = (0, 1.2)  # background\n",
    "#background_param = (0, 3)  # background\n",
    "epsilon = sigma0 / 2.  # Smearing width\n",
    "\n",
    "dummyval = -10 #a value for examples that don't pass one of the measured/ideal selections\n",
    "\n",
    "#Synthetic\n",
    "theta0_G = np.random.normal(theta0_param[0], theta0_param[1],N)  # Generator-level synthetic sample\n",
    "theta0_S = np.array([(x + np.random.normal(0, epsilon)) for x in theta0_G])  # Detector smearing for synthetic sample\n",
    "pass_reco = np.random.binomial(1,1.-eff,len(theta0_G))\n",
    "pass_truth = np.random.binomial(1,1.-fake,len(theta0_G)) # what a concise Toy MC with cuts!\n",
    "theta0_S[pass_reco==0] = dummyval\n",
    "theta0_G[pass_truth==0] = dummyval\n",
    "\n",
    "theta0_background = np.random.normal(background_param[0],background_param[1], int(N*back))\n",
    "theta0_S_withback = np.concatenate([theta0_S,theta0_background]) #smeared synthetic (mc_reco)+background\n",
    "theta0_G_withback = np.concatenate([theta0_G,-np.ones(int(N*back))*dummyval]) #gen synthetic (mc_truth)+background\n",
    "\n",
    "theta0 = np.stack([theta0_G, theta0_S], axis=1)\n",
    "labels0 = np.zeros(len(theta0))\n",
    "\n",
    "#Natural\n",
    "theta_unknown_G = np.random.normal(theta_unknown_param[0],theta_unknown_param[1], N) # Nature, particle-level analog\n",
    "theta_unknown_S = np.array([(x + np.random.normal(0, epsilon)) for x in theta_unknown_G]) # Measured Data analog\n",
    "pass_reco = np.random.binomial(1,1.-eff,len(theta_unknown_G))\n",
    "pass_truth = np.random.binomial(1,1.-fake,len(theta_unknown_G))\n",
    "theta_unknown_S[pass_reco==0] = dummyval\n",
    "theta_unknown_G[pass_truth==0] = dummyval #emulates cuts done in an analysis\n",
    "\n",
    "theta_background = np.random.normal(background_param[0],background_param[1], int(N*back))\n",
    "theta_unknown_S_withback = np.concatenate([theta_unknown_S,theta_background]) #Nature+background\n",
    "theta_unknown_G_withback = np.concatenate([theta_unknown_G,-np.ones(int(N*back))*dummyval]) #Data+Background\n",
    "\n",
    "theta_unknown = np.stack([theta_unknown_G, theta_unknown_S], axis=1)\n",
    "labels_unknown = np.ones(len(theta_unknown))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-10.        ,   0.7809088 ,  -0.56505888, ...,   0.33156939,\n",
       "        -0.36750336, -10.        ])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "theta0_G"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 1.63726592,  0.64124504, -0.41135563, ...,  0.33854484,\n",
       "       -0.60148754,  0.49806421])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "theta0_S"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-10.        ,   1.63726592],\n",
       "       [  0.7809088 ,   0.64124504],\n",
       "       [ -0.56505888,  -0.41135563],\n",
       "       ...,\n",
       "       [  0.33156939,   0.33854484],\n",
       "       [ -0.36750336,  -0.60148754],\n",
       "       [-10.        ,   0.49806421]])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "theta0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 0., 0., ..., 0., 0., 0.])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1000000,)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels0.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1000000, 2)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "theta0.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1., 1., 1., ..., 1., 1., 1.])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels_unknown"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1000000,)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels_unknown.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-17T03:49:29.592393Z",
     "start_time": "2020-11-17T03:49:24.310793Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3168250/177983796.py:30: UserWarning: Matplotlib is currently using module://matplotlib_inline.backend_inline, which is a non-GUI backend, so cannot show the figure.\n",
      "  fig.show()\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA2gAAAFwCAYAAADNDFjiAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/YYfK9AAAACXBIWXMAAAsTAAALEwEAmpwYAABg0klEQVR4nO3dd3xUVfrH8c9D6AQCSJQmxQKKVBMFFCEIoqBiQxewUNeCLuCCKBaahbICgsq6/FSCCyrY0FVQVAjCijQN68KCggaQIiCGjgg5vz8mM056JplkJsn3/XrNK5l7zz33mZthHp65555rzjlEREREREQk9EqFOgARERERERHxUIEmIiIiIiISJlSgiYiIiIiIhAkVaCIiIiIiImFCBZqIiIiIiEiYUIEmIiIiIiISJkqHOgAvM7sGuBuojieuisArwAzndy8AM0vIootOzrnTfu2aANOBCql9LQJGOedO+bUx4FGgB3AUcMCDzrm16WILWl8iIiIiIiJZCZsCDZgDjHfOTQYws0uB5UAVYLx/Q+dcXHYdmVkNYCnwpHPuBTOrBHwJVAKG+DV9ArgTuMQ5l2xmdwCfm1kL51xSsPvKSo0aNVyDBg2yayIiIkXYunXr9jvnonPbXnlBRKR4yy4vWLjcqNrMFgHdnXO/+y1bCJzjnLvAb1lCLgq0J4F7gFres2pmdhfwKlDPObfLzCoDe4CRzrnpfttuBT5xzg0Kdl9ZiY2NdWvX6kSbiEhxZWbrnHOxuW2vvCAiUrxllxfC5ho051xX/+Is1XGgbB666was9R/yiOesVwTQJfV5HJ7hil+l23Zl6vYF0ZeIiIiIiEiWwqZAS8/MIoC2eIY+pl832cyWmdmXZjbbzC5M1+Q8YFe6ZTtTf57v14Ys2tU3s7J+7YLVl4iIiIiISJbCtkADhgK/kO76M2A9nmvC4oArgG3AejNr59cmEvgt3Xbe55X82pBNu4oF0JePmd1tZmvNbO2+ffvSrxYRkRJGeUFERCBMCzQz6wrcC3R1zh33X+ecG+Kc+9B5nAbG4Dlz9ZhfsyNAuXTdep8f9WtDNu2OFUBf/q9jpnMu1jkXGx2d6+vGRUSkmFJeEBERCMMCzcyuBp4FOjvnfsqpvXMuBdgKnOO3eAtQO11T7/Pv/dqQRbttzrmTBdCXiIiIiIhIlsKqQDOza/EUZ1c757alLrvbzKql/t7MzB7LZNO6/HFdGMBCIDb1Ojavy4DTwOLU5wl4JiFpna6vtnjuc1YQfYmIiIiIiGQpbAo0M7sBz9T1jwE1zSzWzGLxTHEfldrsDGCYmZ3vt10/PJN1TPPrbjqeG0Xfk9qmIvBX4EXn3C4A59xhYALwFzOLSm3XG4gGJhZQXyIiIiIiIlkKpxtVvwWUAd7Pps164HlgrpkdwzMF/0k8Z9w+9TZyzu0zsyuB6WZ2O57JPBYBo9L19ySQAiwzsyN4CrHO/jeWDmZfIiIiIiIi2QmbG1WXZLohqYhI8aYbVYuIiL8icaNqERERERGRkk4FmoiIiIiISJhQgSYiIiIiIhImVKBJsTZw4EDMzPdISEgIdUgiIiIFLiEhIU3+69u3b6hDEpFcCqdZHCVM7d+/n+eee46FCxeyZcsWTpw4QXR0NLVq1aJFixZcccUVdOzYkfr164ckvueee47k5GSGDh1K1apV06ybMmUKTz31FDfffDMrV64slHji4+NJSkqib9++NGjQIMP6Y8eOccUVV2BmLF++nAoVKhRKXCIiRVWDBg3Ytm2b73mfPn2Ij4/PtG1CQgIdO3bMsHzWrFl5LlKSk5N57rnnqFq1KkOHDs1TH4XtsssuY/fu3cybN69IxDwmYUzObeJybiNSHOgMmmRrw4YNXHTRRTz//PP06NGDJUuWsHXrVhYvXszdd9/N4sWL6devH/fff3/IYnzuuecYO3YsycnJGdZVqVKFmjVrUrZs2UKLJz4+nrFjx5KUlJTp+g0bNvD111+zbt06NmzYUGhxiYgUVWvWrGH37t20bdsWgNmzZ/PKK69k2tZbmKxevRqAd955h927d/OnP/0pz/tPTk5m7NixPPfcc3nuo7CVLVuWmjVrEhUVlXNjEQkrOoMm2br77rvZu3cv8+fP59Zbb02z7qKLLqJ9+/bExMSEKLqiqVWrVtx2220AtGzZMrTBiIgUAdHR0YCn6ChdujSnTp3igQceIDY2lhYtWqRp6y1MTpw4AUD16tWpWbNmoccsIpJXKtAkSwcPHuTLL78E4Jprrsm0zQUXXECXLl34/fffCzO0Iq106dLMmzcv1GGIiBRJPXr0YOvWraxZs4Zbb72VtWvXUqVKlVCHJSISNBriKFlKSUnx/b5r164s282YMYPnn38e8Fwn4H9RspmluU4gLi4uzboxY8ZkOpHHO++8Q0xMDBUqVCA6OpoBAwZw8ODBNPvt27cvZua7LqFhw4a+PjK79ssrN337++KLL+jevTs1atSgXLly1K9fn4EDB7J169Y07caMGYOZsWzZMgA6duyY5nX5t8ns2Phbvnw5N9xwA2eeeSZlypThrLPOokuXLkybNo0DBw5kGauISHFXrlw53n77bc444wy+//57BgwYEND2O3bsYNKkSVxxxRXUqlWLsmXLUq9ePfr3788PP/yQoX2DBg1o2LAhANu2bcsw8caJEyfSLIuLi0uzfdOmTbPMTZ07d06zbVJSEvHx8cTExFCxYsU0+QNg2bJlDBo0iGbNmlGlShUqVapEq1atePbZZ/VFqUgxogJNslStWjVq1aoFwH333ce+ffsybVerVi1f8lqzZg2TJk0CPMVY+nH/7777LgsWLKB06dJs2LCB4cOHM2XKlDTXFsyZM4f333+f2bNns2rVKq677jpeffVV7rjjjjT7nTZtGrt376Zu3boArF69mt27d7N7927WrFmTaaz+fa9evZru3btn2rfX9OnTiYuLY8+ePbz55pt8++23PP3003zwwQdcfPHFaSYeGT58eJrX4b3uwfvwb+Md4piZqVOn0qFDBw4cOMDbb7/N999/z5w5czh69ChDhw4N+D8jIiLFTb169Xj99dcpVaoUb7/9NtOnT8/1tk8//TSPPvooV199NZ9//jn/+9//mDZtGmvWrCEmJoaNGzemab9mzRrf9Wx169ZN87k+bdo0ypcvz+7du3nnnXcy3d+yZct826f31ltvpcljEyZM4NNPP+Xll19m/fr13HTTTWnaX3311Xz66ac8+eSTrF+/npUrV9KzZ08ef/xxunfvnuaLVREpujTEUbL1+OOPc//997N06VIaNGhAjx49uPnmm+ncuTOVKlXK0D46OpqBAwcyatQoli9fTkpKSppZCqtXr86HH37ItddeS5MmTXzLq1Sp4pvIY+XKlfz3v//1fWv48ssvs2jRIj788EO2b99OvXr1AIiKiiIqKoqIiAjfvnO6ziB93zNnzmThwoUZ+gb48ssvefDBBznrrLNYunSp7/U2atSIc845h8svv5zevXvz3XffUaZMGSIjI4mMjPS9jsyue/C2yWrmxhUrVjB8+HDq1q3Lxx9/7NtngwYNaN26NRdeeCHOuWxfo4hISdClSxfGjBnDqFGjGD58OK1bt6Z169Y5bnfGGWcwfPhwHn/8cd+yc889l0svvZSzzz6bhx56iI8++si3Ljo6mqNHjwIQERGRaZ6pWbMm1atXz3J/hw8fznRdtWrVfP0CJCYmsnLlSl+OGjdunO9SA4D69eszd+5cYmNjfcuaN2/O6dOneeyxx3jnnXcyXC8uIkWPzqBJtgYNGsS0adOoWrUqx44d47XXXuPGG2/kjDPO4JprrmHWrFm+C7G9qlWrxo033sjp06eZPXt2mnXHjh1j3rx52Z4Fuuuuu9IM6YiIiODiiy8G4D//+U++Xk9mfbdq1SrTvsePH09KSgr33ntvhmL0sssuo1mzZiQlJaVJ5Pk1YcIEUlJSGDBgQIZ9VqlShZ49e2ZaGIuIlESPP/441157Lb///ju33XZbroaAP/3000yYMCHD8jp16lCnTh0+++wzTp48WRDh5uj+++9Pk6OaNm3Knj17fM83b96cpjjz8hamCxcuLPggRaTAqUCTHA0ePJgdO3YQHx/PjTfeSGRkJL/99huffPIJ/fv3p3Hjxnz11VdptvEWYK+++mqa5W+99RaVKlWia9euWe7v3HPPzbDM+y3jr7/+mq/Xklnf3m89/fs+ffo0S5YsAeCSSy7JtK9zzjkHIM23m/lx+vRpli5dmu0+J0+ezNy5c4OyPxGRos7M+Oc//0nDhg3Zvn07d911V65GGbz55ptcc8011K1blypVqvhGN+zcuZOTJ0+yf//+Qog+o8aNG2e7/sCBAzz22GPExMQQHR3ti/u6664DYOfOnYURpogUMBVokiuRkZH06dOH9957j19++YVPPvmEu+66izJlyrB9+3ZuvvlmDh065GvfqVMnGjRowJYtW3yTZgC88sor9OnTh9Klsx5de8YZZ2RYVqZMGcBTxORHZn17Y/Hve//+/Rw7dgzwzBjmTYL+D++Zs2AlRP99eqeUFhGR7FWrVo133nmH8uXL89FHH2V6dszfPffcQ69evfjpp5947rnnWLlyJYmJiSQmJlK7dm2AkJ1By+6zf/fu3Vx88cU888wztGrVirfeeotvvvmGxMREXn75ZSB0cYtIcOkaNAlY2bJl6dKlC126dOEvf/kLl19+Obt372bRokW+CUHMjH79+jF69GheffVVOnTowJYtW1ixYoUvkWTFf3hHsOWl79dff52mTZtmuT4yMjI/IWWqII+BiEhx06pVK2bMmEH//v154oknuOyyy6hfv36GdqtXr2bmzJmUK1eORYsWcfbZZ6dZn92Xh/mR22uHs/vsf/LJJ9m2bRtdu3bNkEd/+umnfMUnIuFFZ9AkW88880y2Q/hiY2Pp1KkTAD/++GOadX379vXNsHXo0CFeffVV2rVrR6NGjQo05mCoUaMGFStWBKBChQqcd955WT6CdQNU/31mNWOmiIhkrl+/fgwcOJDTp0/Tq1cvfv755wxtli9fDngme0pfnOWXd6KPzEZ6BGPIpDf2zp0757svEQlvKtAkWzNnzuS9997Ltk358uWBjEMz6tWrR+fOnTl27Bhz5sxh9uzZ9O/fP+gxliqV9m18+vRp9uzZk2HykkBERERw5ZVXAmQ5PfKGDRto2bJlhklC0scDsGfPHt8sYNnts2PHjgBZ3iZg/Pjx9OjRQzM5iohk4oUXXiAmJobdu3fTr1+/DOuzGyafkpKSaVEHmX+uHz9+nD179vimto+KigIyv1Y6/X0z8yK72LO7V6mIFD0q0CRHc+bM4Zdffsl03e7du1myZAnly5fPdOIP72Qhjz76KIcPHy6Q6X+rVq0K4CuAvv32W2rVquWb5COvHnnkEUqVKsXMmTMznSL5ySefJCkpiQ4dOmQbT3JyMrVq1cowo2VmHn74YcyMWbNm+a5H89q7dy9/+9vfOPPMMzUEUkQkE96bWFevXp3//e9/GdZ7J2DavHkzSUlJadZ9+OGHWX6x5y2+/L9o+8c//kGtWrU4fvw44DkrV6FCBb7//nuOHDmSZvvcfP7nxBv7xx9/nGHd22+/ne/+RSR8qECTbJkZe/bsoX379rz22mts2rSJHTt2sHbtWqZNm0br1q05fPgwzz//vO/ian/eKfkPHjyY5RTxR44cYc+ePb6Lmw8cOOCbVtj7DaU3AR48eJA9e/ak+Saxffv2AMydO5etW7cydepUKlWqRGxsbL76vvzyy5k6dSo7d+7kyiuv5JNPPmH79u2sXLmSXr168e677/Lmm29muAbNG8/8+fP54YcfmDhxIqVKleKKK67wxZN+n974rrjiCiZPnsy2bdvo1q0bK1asICkpiYULF3L11VcTHR3N008/HfDfUUSkKNu3b5/vs9L72Z3VlPoNGjRg7ty5mZ716tixI1dffTUnT56ke/fuLF68mK1btzJnzhwGDhzouwZt3759aYaaR0VF0aJFC/bv38+CBQvYuHEj8fHxxMbG+vJa+fLl6du3LydPnuSOO+7g66+/5rvvvmP48OG+4ZTeER7e2NPnHe/r9OYIf48++iiVK1fm008/ZdCgQSQmJvLtt98yePBg3/T6J0+eZM+ePRw5csT3+8GDB4E/cl764lFEwpBzTo8QP2JiYly42rt3r/vnP//p7rjjDteyZUtXs2ZNV7p0aVepUiV34YUXurvvvtslJiZm28fgwYMd4L766qtM148ePdoBGR7OOTdr1qxM1/3444++7X/99VfXv39/V6tWLVexYkXXqlUrt3DhwqD07ZxzK1ascDfeeKOLjo525cqVc+ecc47r3bu3W79+faav57fffnPDhg1zZ599titfvry74IIL3OzZs7ONZ+nSpWn6WLZsmevevburUaOGK1++vGvcuLEbPny4279/f7bHWkTCE7DWFZO8EAr169fP8LnZoUOHbLcZM2ZMpp+vx48fdyNHjnQNGjRwpUuXdlWrVnVdunRxn3/+eZr91K9fP812GzdudFdddZWrWrWqq1q1qrv66qvdpk2b0rQ5ceKEe/DBB12tWrVc2bJl3QUXXOBeeukl9+OPP2Yae58+fTLNCbNmzcr0Nf33v/91N954o6tataorXbq0q1evnrvvvvvcm2++mWb70aNHu6VLl2ba9+jRo3N/4AvR6KWjc3yIFCfZ5QVzupYl5GJjY93atWtDHUaBmTx5MrNmzeK///1vqEMREQkJM1vnnMt4h+EsFPe8IJLemIQxObeJy7mNSFGRXV7QEEcpcK+99lqBTA4iIiIiIlLcqECToDp8+DCPPfaY7/nq1avZvHkzd955ZwijEhEREREpGnSjagmqo0eP8swzz9CkSRNiYmJ48MEHueeeezJMwS8iIiIiIhmpQJOgKl++PM2bN+fPf/4zZcuW5frrr2fixImhDktEREREpEhQgSZBVbVqVdavXx/qMEREREREiiRdgyYiIiIiIhImVKCJiIiIiIiECRVoIiIiIiIiYUIFmoiIiIiISJjQJCEiIiIiElIJ8Qk5N4or6ChEwoPOoBVTzrlQhxCwohgzKG4RKRqK4r/5ohgzFN24w52Oq5QUKtCKoXXr1hEbGxvqMAI2adIkHn/8cU6dOhXqUHItHI/1xx9/TJ06dTCzbNsVxeMtInkTjp9VuVEUP6eK6rEuCori+0EkL1SgFTPvv/8+7dq149Zbbw11KAHr3bs38+bNo0uXLhw/fjzU4eQoN8f6X//6Fx07dqRq1apUrlyZNm3aMHv27AKJ5+jRo9x3331069aNXbt25di+qB1vEckb5YXCU5h5YcuWLTzxxBO0bt2aqKgoypYtS506dbjllltYsmRJfl5GtoKZ13744QcGDx5Ms2bNWPH6CpbPWc7q91azZfUWTh4/maF9UXs/iOSZc06PED9iYmJcMHzzzTeuQoUKbsSIEUHpLxR27tzpoqKiXM+ePUMdSrZyc6zHjRvnAHfzzTe7b775xm3cuNHdc889DnADBw4Majzff/+9O++881zjxo3d/PnzHeA8/7yzV1SOt0hRB6x1ygt5UlQ+pwozL3zwwQeuVKlSLjIy0o0fP959/fXXbvPmzW727Nmudu3aDnCPPfZYMF5WgcTvnHOfffaZK1++vKtcubKbPn26i70h1sXeEOvOu/Q8F1EmwpUpX8ZdctMlrkOfDr6Hc0Xn/SCSk+zyQsiLEz2Cl4gvvfRSV716dXfw4MGg9Bcqo0ePdoBbuHBhqEPJUk7HOiEhwQGuVatW7tSpU2nWXX/99Q5ws2fPDlo877//vvvLX/7ijh075n788cdcF2jOFY3jLVLUhapAU14oPIWZF2bNmuUA9/rrr2dY95///MeVLl3aAS4hISHwF5KFYOe15s2bO8DNnDnTOefSFGLntz3fAe6MumdkKNCcKxrvB5GcZJcXNMSxmFiyZAmrV69m4MCBVKlSJdTh5MuQIUOIiIhg4sSJoQ4lU7k51mPHjgVg8ODBREREpFn317/+FYBx48YFLabrrruO6dOnU6FChYC3DffjLSJ5o7xQeEKRFypXrsxtt92WYXmzZs1o3bo1AG+//Xau+8tJsOP//vvvAbjssssyrIuKjgIgeU9yptuG+/tBJL9UoBUTc+fOBaBTp06Zrt+4cSNmxkUXXZTp+oMHD1KqVCnOPPPMoMa1YsUKevfuTYMGDShfvjxmlulj5syZvm2qVatGTEwMy5Yt46effgpqPMGQ07Heu3cvy5Yty7LN5ZdfTrly5di6dSvr1q0LSkylSuX9n3K4H28RyRvlhcJT2Hmhd+/e7Ny5M0Oh5FW3bl0ADhw4kKv4c1IQea158+YAbNiwIcO6o8lHAShVOvPcFu7vB5H8UoFWTHz++ecANG3aNNP1a9euBSAmJibT9V9//TXOOS6++OKgxTRu3Djat2/PG2+8QfXq1bn55ptp3759prMLtmrVKs3zZs2aAX+8rnCS07Fet24dKSkpVKpUibPPPjvD+jJlynDOOecAsGbNmoILNADhfLxFJG+UFwpPYeeFsmXLUrly5SzX7969O9t4AlUQeW3GjBnUqlWLBx98kEWLFpFyOoWU0ykc2HmArWu2AlC9TvUstw/n94NIfqlAKwaOHDnCtm3biIiIoGbNmpm28SbirKb+9X7jFaxEPGfOHEaPHk2lSpX46KOP+Prrr3n99ddZtmwZ8+fPBzxnfbZu3crx48e55JJL0mzv/fYvs2/WstO3b98sv43N7pGUlJSr/nNzrLdu9SSWs846K8t+atWqBXhmsAoHeT3eIhKelBf+UNLywq+//sqqVasoX748/fv3z1dfXgUR/8UXX8ymTZvo06cPN910E8vnLmf53OV8+9m3nDx+kqizojg39twst1fekuKsdKgDkPzbtm0b4Dnln9VQt5y+KQ1mIj5+/DgPPvggAC+++CLdunVLs75Hjx40adKEjRs38tVXX9G7d+8MfdSoUQMg1wnSq1atWjRu3DjgmMuUKZOrdrk51ocOHQKgYsWKWfbjvVbs4MGDgYRZYPJ6vEUkPCkv/KGk5YWpU6fy22+/MWXKlGwLqkAURPz79++nd+/eLFmyhEceeYRF6xdhZvy6+1dSTqVQ96K6RJTOfAgnKG9J8aYCrRg4fPgwAOXKlct0/enTp1m/fj0REREZhox4eRNxVok6EG+99Rb79+8nJiaGu+66K9M2jRo1YuPGjVmOj/e+Fu9ry63x48czfvz4wAIOQE7HOrc8k/eQ482kC0tej7eIhCflhT+UpLywatUqxo8fT48ePRg6dGi+4glUoPHfdNNNrFixgnHjxvHEE0+wou8KACKrR/LT/35i7QdrufCKC6kSnfmkK8pbUpxpiGMxcOrUKYAsLxbeuHEjx44d48ILL8z0269Dhw6xZcsWqlWrRsOGDfMdz8cffwyQ7Y06vd/GnXHGGZmu974W72sLFzkda8A3g9exY8eybHPixIk0bUMtXI+3iOSN8kLhCZe8sGnTJq677jo6d+7M3Llzg/oFYLDj/+KLL1ixYgURERG+M6v+ajeqze/Hf/cNd8xMuL4fRIJBZ9CKAW9yPXky8w+x3F4IntW3qIFKTEwEoG3btpmuP378OKtXrwbg0ksvzbTNb7/9BkClSpUC2vfIkSN57733AtoGPBcZ16lTJ8d2OR1rgHPP9YyZ//nnn7Ns472A23tRdajl9XiLSHhSXvhDScgLmzdvpnPnzrRt25a33nqLsmXLBtxHdoId/3/+8x/Acx1ZZGRkhvWlIkpRvnJ5jv56lL1Je6l7Yd0MbZS3pDhTgVYMeMeYe799TM+biFu2bJnp+oULFwLBuxB87969QNbfon300UccOXKE5s2b+z700/MOWQh0eufdu3ezefPmgLYB+P3333PVLqdjDZ7/8JQqVYqjR4+yY8eODDNe/f777/z4449A1hfnF7a8Hm8RCU/KC38o7nlhw4YNdOrUiXbt2vHGG2/k+tq5QAQ7fu+ZuNyc5fvt6G+ZLlfekuJMQxyLgdq1a1OpUiWOHTvGkSNHMqz3XkeQ2U2MDx48yOuvvw4E5zoDgKgozw0mv/vuuwzrDh8+zIgRIwB8PzOzZ88ewHNNQiDi4+MzvSN7To8GDRrkqv+cjjV4ksUVV1wBZD7977///W9OnDhBw4YNw6ZAy+vxFpHwpLzwh+KcFxITE4mLi6NTp07MmzcvTXH26aef0qdPn1z3lZ1gx+/9G+7YsSPTYZMuxXHiiGfIZNkKmZ8NVN6S4kwFWjFgZr5hI+mT36lTp1i/fj0Ab7zxhm9IAHi+VfzTn/7Ezp07ATKd5eqzzz7DzLL8ljUzV155JQATJkxIc/Hu/v376dGjBz/++CPXX389t99+e5Z9eL/tvPzyy3O938KQ3bH2N3r0aACmT5/O6dOn06ybOnUqAKNGjcqwXV6OdzCE6/EWkbxRXig8BZ0XZs2aRcOGDTNMdLJ69WquvPJKrr/+ev75z39muAZu586dvptL+8trnglm/F26dOHMM8/k9OnTvPjiixm22bNlD6d/P42ZUePsGpnGE67vB5GgyMu3SnoE9xETE+Pya/r06Q5wL774Yprl33zzjQNc3bp1XYUKFdxZZ53lunbt6tq0aeMqVKjgYmNjXZkyZRzgLr74Yjd79uw028+dO9cBrnv37rmOJSkpyUVHRzvAnXXWWe7WW2911113nYuMjHSAu/HGG93Ro0ez3P706dOuRo0a7qyzznKnTp0K7EAUgqyOdXqjR492gLv55ptdYmKi27hxo7v33nsd4Pr27ZvpNnk53l579+51u3fvdqtXr3aAA9zu3bvd7t273d69e7PcLtyPt0hxAKx1ygvKC3nICxdddJEDXGRkpG/ZqlWrXJUqVZyZuYsvvtjFxMRkeDRo0MDVr18/Q3/5yTPBit855z755BNXoUIFV7ZsWTdx4kR3yY2XuEtvutSde+m5rlTpUg5w515yruvQp4Pv4RXu7weR3MguL4S8OPEFAtcA7wIJwArga+B+wNK1M+Ax4JvUdsuB2Ez6awJ8Bvw7te0zQOlQ95XZIxiJODk52VWuXNm1bds2zfL/+7//c4Dr06eP+/jjj13Lli1duXLlXO3atd0DDzzgkpOT3ZAhQ1yFChVcy5Yt3caNG9Nsf8899zjAvfbaawHF88MPP7g777zT1axZ05UpU8ZFR0e7a6+91i1YsCDHbT/66CMHuFGjRgW0z8KS1bHOzIIFC1yHDh1clSpVXKVKldyll17qXn311Szb5/V4O+dc/fr1fYVZ+kdmSdor3I+3SHEQigJNeaHwFGReePbZZ11kZKR78MEHfcu8hVJOj8w++/OTZ/ITf5sebdzopaPTPB745wMu5voYV71OdWelzFkpc+UqlXPRDaJdy64t0xRn/gVauL8fRHKjqBRo+4Fhfs8vBX4DRqZrNwr4Hqia+vwO4CDQwK9NDeBn4IHU55WA9cC0UPaV1SMYidg556ZMmeIAt3DhQt8y7zdbL7zwQsD9bdmyxZegT5w4EZQYcyM2NtbVqVPHHTp0qND2GajMjnV+6XiLFF+hKNCcU14oTAWRF4ItVH8/51yG4iz9I30xltnDqyi8H0Rykl1eCKdr0NYA071PnHOrgc8B3xWuZlYZeBh43jmXnNpuDp7izv/K4iF4zmj9PbXNUWAycL+Z1Q5hXwVqyJAh3HLLLQwcONA3Nts7U1egk1EcO3aMLl26ULt2bd57771834Azt4YPH86GDRt4++23qVy5cqHsMy8yO9b5oeMtIgVBeaHwBDsvBFuo/n7BVlTeDyL5ETYFmnOuq3Mu/Zy2xwH/6XvigIrAV+narQS6+T3vhqcq9b+K9UsgAugSwr4KVKlSpXjjjTe44YYbiIuL4/fff+fbb7+lTJkytGjRIqC+KlasyHPPPce6detyPZNVfr300kvMmzePJUuW0KZNm0LZZ16lP9b5peMtIgVBeaHwBDsvBFso/n7BVpTeDyL5Ebb3QTOzCKAt8LLf4vNSf+5K13wnUN/MyjrnTqa2+yaTNgDnh7CvAlemTBlmzJjBnXfeybfffstvv/1Gq1atKF++fMB9XX/99QUQYdYuu+wyNm3aVGRuOul/rINBx1tECoLyQuEJdl4ItsL++wVbUXs/iORV2BZowFDgF8B/Xlnv7ebT37XQ+7wicDK1XVZtvP+qQ9FXofFO+esZ4lo0NG/ePNQh5In3WBc1RfV4i0jeKC8UnqKaF8JdUX0/iAQqbIY4+jOzrsC9QFfn3HG/Vd47QKYfOO19fsyvXVZtjoawLx8zu9vM1prZ2n379qVfLSIiJYzygoiIQBgWaGZ2NfAs0Nk591O61VtSf9ZOt7w2sM1vGOGWLNqAZ6bFUPXl45yb6ZyLdc7FRkdHp18tIiIljPKCiIhAmBVoZnYtnuLsaufcttRld5tZtdQmCXgmDmmdbtO2wCK/5wuB2NTr2LwuA04Di0PYl4iIiIiISJbC5ho0M7sBmAn8GahpZjVTV92DpxD61Tl32MwmAH8xs9eccwfNrDcQDUz06246cHfqtjPMrCLwV+BF59wugBD1JSIiIlLiJMQnhDoEkSIjbAo04C2gDPB+Du2eBFKAZWZ2BHB4hkMmeRs45/aZ2ZXAdDO7Hc9kHovw3Ew6ZH2JiIiIiIhkJ2wKNOdc2ZxbQeqdt59KfWTXbgPQKdz6EhERERERyUpYXYMmIiIiIiJSkqlAExERERERCRMFUqCZWRkza18QfYuIiIiIiBRXBXUNWnVgKRCRU0MpOFM//S4k+33wqkb52v6DDz7gpZde4siRI5gZx44do1q1anTt2pVbb72VunXrBinSwrNgwQKSk5Pp27dvmuXDhw9n+/btzJ8/PzSBiYjkw5iEMaHZb1xg+23QoAENGjTwPU9MTASgZcuWvmVJSUkkJSXlO7bExEQWLFjAmDF/xPjBBx/wzDPPsGrVKpYuXUpcXFy+9yMixVeeCjQzuxxoAVQj8yIsMj9BSck1ePBgli9fzvz58zn//PMBOH36NC+++CJDhgzh6NGjPP744yGOMnALFiwgKSkpQ4FWt25dzCw0QYmIlCAJCQm+370Fkv8y/wIuPxITExk7dmyaAq179+40b96chg0bBmUfIlK8BVSgmVlt4COguf/idM1c6jKXv9CkpJkzZw5///vf+e6779IksYiICAYPHsyKFStCGF3BGDp0aKhDEBEp9nLzWavPYxEJF4Feg/YcnjNnXwMvAeOBseke44ApwQtRSorJkycTFxeX5TeMjz/+OF26dAHAOcekSZNo2bIl7du357LLLmPatGmkpKQAMHPmTFq2bImZsWDBAnr06EGrVq1o3bo1GzduTNPvzp076dmzJ61atSIuLo7OnTuzdu1a3/qbb76ZmjVrEhcXx/Tp0+nWrRvR0dHceOONAPztb3/j0ksvpWPHjrRu3Zp+/fqxf/9+3/YDBw7k448/JjExkbi4OOLi4khMTGTcuHFccMEFGc6geeNp1qwZMTExxMXF8dVXX/nWDxo0yDdc580336R79+40atSIHj16cOjQobz/AUREiqncFF/nnHMObdq0wcyIj4+nZ8+evudTpkzx/e496/bee+/58ox3aOQLL7zAhAkTAHyf9/Hx8Wn2k5SURO/evWnTpg1NmzZl+fLlQXylIlIcBDrEsTMwwTn3aHaNzKwm8Nc8RyUlzrFjx1i/fj1DhgzJsk3z5n+cuH3sscd48803WbVqFdHR0ezfv59LLrmEEydO8PDDD3P33XfTqFEjOnbsyL/+9S/mz59PqVKluO666xgyZAiffvqpb79xcXF07dqVN954AzPj7bffpn379mzcuJEGDRrw7rvv0rdvX959913uv/9+Fi5cSGJiIn/7298AeOmll3j//fdp2rQpKSkp9O/fn759+/Lhhx8C8PLLL9O3b1+SkpLSDKdp2bIl9erVo1+/fmmOQ1xcHG3atGH9+vWUKlWK//u//+PKK69kzZo1XHTRRcyYMYMxY8YwadIkkpOT+eCDDzh8+DDnn38+zz//PI899lgw/zQiIiWC/zDEOXPm8P7771OpUiV69uzJVVddxc0335zmC8SbbrqJatWq0bFjR9+yBx54gMjISPr165fm897fvHnzWLBgAeXKlWPo0KH069ePLVu2FPTLE5EiJNACrQwwOxftfgE65thKJNWvv/6Kc47IyJwvXzxy5AhTp05l7NixREdHA1CjRg1uu+02Jk+ezMMPP5ym/V133UWpUp6TxZ07d2bs2LG+da+//jpbtmzh8ccf953J6tGjB/fffz8zZsxg0qRJvrbVqlXj1ltvBTzF1dy5cwH47LPPfEm7VKlS9OrVi27duvHbb79Rrly5gI6DN56PPvrIF/OAAQMYM2YMEydO5LXXXvO1PX36NAMGDACgcuXKtGnTJs2Zv1AKxgQ1+Z1sRkQkr26//XYqVaoEwJtvvgkQlAlEAHr27OnLDVdeeSXTpk3j4MGDREVFBaV/ESn6Ai3QvgYq5qLdaeDHwMORkqpatWqYGYcPH86wbuTIkaxcuZL9+/dTtWpVpkyZwokTJ5g9ezYLFy70tTt06BCVKlXi8OHDVK5c2bfcf9bHqKgokpOTfc+//vprSpUqxW233ZZmn1FRURw8eDDNsnr16mUa+48//siDDz7I3r17KVu2LMnJyaSkpLBnzx7q168f0HHwxnPuuef6lpUqVYrzzz+fdevWpWl75plnUqZMmTQxb9++PaD9iYhIRll93geDf06qUqUKAMnJySrQRMQn0AJtFDDWzG51zv2WTbtoPAWaptmXXKlYsSItW7Zk/fr1GdaNHz8egL59+6YZMjJs2DD69++fY98REX+8DbOaMfGzzz6jdOns/zn49+O1du1arr76asaOHcvIkSN91yd07NgR5/I2T05mMWbWV/p4zCzP+xQRkT9k9nmf2WfzqVOngtK3PrtFxF+gk4TUB/YDO8zsRTP7q5n1MbO7/B/AbTn0I5LBsGHDWL58OZs3b862XZMmTShfvnyGyT6SkpK47777AtpnTEwMKSkpbNq0Kc3y+Ph45s2bl+P2y5Yt49SpU9xxxx2+5H3y5MkM7bzDFb3rjx8/nmU8p0+fTnM9QkpKClu2bCEmJiZXr0lERILPe4bLfzKmHTt2ZGjn/3mfkpKS6cgQEZHsBFqgxQN9gBrAvcDfgFeBWeke04IXopQUt99+O4MGDeLmm2/OUHxt3LiRjRs3UqpUKSIjIxk+fDjx8fG+Yu73339n5MiR1KlTJ6B99urVi0aNGjFq1Ch+//13ALZu3crYsWNp1apVjtu3aNECgI8//hjwfAuaWWFXs2ZNDhw4AMCUKVMYPXp0tvE89dRTvhkpX3nlFX799VdGjBgR0GsLZ222z8zxISISTqpWrco555zjG8lx4sQJ3njjjQztatasCcCBAwdYvXo1nTp1KswwRaQYsEBOq5tZCjAfyPzr/z9UBHo45zTEMRdiY2NduEzuEA7ef/99/v73v3PkyBHMzHdtWefOnenfvz8NGjTAOceUKVN45ZVXiIqK8s3Q+Mgjj2BmvP7660yaNIn169fTunVrpk6dyrfffsuUKVPYvHkzHTp04B//+AeNGzdm9+7dDBs2jHXr1lG7dm1Kly7NqFGjuOKKKwDPJCOLFy/mxIkTtGzZkvHjx9O2bVtfvFOnTmXatGnUqlWLs846i4YNG/Lcc8/RunVrJk6cSIcOHfjhhx/o0aMHFSpUADz3fPvnP//J66+/7otn0qRJXHrppezatYthw4bx7bffUq5cOSIjI5k4cSJt2rQBYMSIEcyfP589e/bQpk0bFi1axLBhw3j33Xc5ceIEbdu2ZdGiRYX/h/Oz8pXh+e6j7YBngxCJSHgws3XOudjctldeKBjbt2/nrrvuIjExEfBM+DRr1iwaNmzIkiVLePTRR1m1ahUtWrSgdevW/OMf/0iz/bJly7j//vuJjIykfv36XHPNNfTv35/WrVvz6KOP0r17d06dOsUtt9zCtm3bKF26NOPGjaN8+fJp+h49ejQRERGMGjXKl6e8+aK4iusbl+8+EuIT8t2HSLjILi/kpUCr6Zzbm0O7msAu51ygZ+hKJCViKW5UoImkpQJNSjoVaCJpZZcXAi2gngByM5g6GeiXUyMRERERERH5Q0CzODrnns5lU02zLyIiIiIiEqBAp9nPrerAUjTNvoiIiIgEQU7DJDUEUoqLbAs0MysHXAQkOudSUqfQzw3dbVFERERERCRAOZ1BWwFcDMwDeuOZZj83s4pYLtuJiIiIiIhIqpwKtFJ4ii3zW/YWuZxmPx9xiYiIiIiIlDg5FWjt8Axx/MZv2eBcTrN/az5jExERERERKVGyLdCcc8cB/xuxjAWO5KLfw6ltRUREREREJJcCnWY/V0WXc+4oKtBEREREREQCkqdp9s2sFNANaA/UwTMhyC7gC2Chcy4laBFK3i0dH5r9dhyZp83mzp3LSy+9ROnSpTl9+jSHDh2iWbNm9O/fn44dO7Jr1y5atGjB4sWLadWqVZCDzmjlypWMHDmSZcuWMWvWLPr27ZvrbZOSkoiPj2fo0KFUrVrVt3zdunV07dqV9evXU6tWreAHLSJSiMaMGVNk9rtz505uv/12EhMTAWjZsiXOOQ4dOsT555/PoEGDiIuLC6jPxMREFixYELLjICLFU8AFmpm1Bv4JnOtdlPrTAcOArWZ2p3NuVXBClJJg3rx5DBs2jNWrV1OvXj0A9u7dS+fOnXn//ffp2LEjFSpUoHHjxkRGRhZKTG3btiUhIQEzy7lxOklJSYwdO5a+ffumKdAqV65Mo0aNKF++fBAjFRGRnNSpU4eEhARfEZaQkACAc4533nmHm2++mT//+c9MnDgx130mJiYyduxYFWgiElQBFWhm1hT4DKgE7Mczecg+PEVaNNASOA/4zMzaOuf+G9RopdiaP38+V1xxha84AzjzzDMZOXIk33//PQDVqlVjxYoVoQoxKBo1alTkX4OISHFiZvTo0YOoqCi6dOlCixYt6N27d6jDEpESrFSA7Z8GTgF/As5yzl3tnLvDOXe7c64LcBbQC/gdeCq4oUpxVrZsWVatWsWBAwfSLO/VqxejRo1i+/btxMXFUb58ed83latXryYuLg4zY8qUKQwYMIDLLruMJk2asGzZMjZv3kzv3r1p1qwZnTp1Yvfu3QAcOHAgQ18//vijr6/4+PhsY/3yyy/p1q0b7dq1o0OHDrRr1873TSzA22+/zdChQwHo2bMncXFxTJgwIU28/vtwzjFp0iSaNWtGmzZtaNasGc8++yzOeW4l+MEHH9CmTRvfdr1796Z169Y0bdqU5cuX5/mYi4jIH6666ipiYmL429/+BsCHH35Ix44diYuLo127dlx11VWsX7/e1/6FF15gwoQJAMTFxREXF+f7bM9pWxGR7AQ6xLE9nmn238pspfP8j3KemZUHnstnbFKC3HPPPbzzzjucd9553HHHHXTv3p327dtTtmxZAOrVq0dCQgINGjTwbXPppZf6hiC+8cYbfP7551SpUoXhw4dz55138uc//5m5c+eSkpJC27ZtGT16NDNnzqR69eoZ+mrYsGGuhzMuXryYZs2a+YbBfP7551x33XVs2LCB+vXr06NHD2rUqEHHjh1588030+wns3089thjzJo1i9WrV3P22Wezfft2WrduzaFDhxg3bhzdu3enefPmNGzYkHnz5rFgwQLKlSvH/fffT79+/diyZUveD7yIiPi0adOGGTNmcOzYMd5++21uu+027rvvPgBeeeUVunbtyqZNm6hSpQoPPPAAkZGR9OvXL82XdECO24qIZCfQM2ilgWW5aLcUKBN4OFJSxcXFsXLlSjp16sTMmTO56qqrqFmzJsOGDePo0aM5bn/99df7kl7Hjh3ZsWMHHTp0wMyIiIigffv2rFmzJiixDho0iFGjRvmed+rUicqVK7N48eKA+zpy5AhTp06lX79+nH322YCnGO3bty/PPvtshtfes2dPypUrB3i+7d26dSsHDx7Mx6sRERGvqlWr4pwjOTmZp59+mgEDBvjW3XHHHezevZtVq3K+xD4/24qIBHoG7VugJrA9h3Y1ge/zFJGUWDExMbz11lscOXKETz75hPj4eKZMmcK3336bY/FTp04d3++VKlXKsCwyMpLk5OSgxJmSksKjjz7KunXriIiIwMz49ddf2bVrV8B9bdy4kRMnTtCoUaM0yxs3bszx48fZuHEjl1xyiW953bp1fb9HRUUBkJyc7PtdRETy7tdff8XMqFatGjt37uS+++5j06ZNlC5d2jf6ITef9cePH8/ztiIigRZok4CxZnadc+50Zg3MrDSee6DNzG9wUnLs37+fyMhIypcvT2RkJLfccgu33HIL999/PzNmzCA5OTnNbIjpRURE5LjMe02XV/qhhqdOncpVrF27dqVMmTJ88sknVKtWDYAGDRpk6D8Q6WPJqi//1+TdJj/7FRGRP6xcudI3/X6HDh2IiYnhs88+o0KFCoDnczenz9xjx47leVsREchmiKOZtU//AA4Ae/BMpf+Emd1mZnGpj9vMbBSwBagAbCyclyDFwfDhw3nvvfcyLG/cuDFmRqlSgY7GzVlUVBSHDh3yPd+xY0eO2/zyyy8kJiZy3XXX+YozgJMnT6Zplz7erIYhNmnShPLly7Np06Y0y7/77jsqVKhAkyZNcoxJRETyb/HixXzzzTc89NBD/O9//2PXrl306NHDV2Cl/5yHtJ/1KSkpHD58ONfbiohkJbv/9SbguZYs/eMuoB4wBngD+Dz18QYwOnVd+9RlIrk2depU9u/f73u+b98+4uPjue666wrkouqYmBhWrFjB6dOek8GzZs3KcZvq1atTt25dlixZwu+//w54Jv7wzhDpVbNmTcAzY+SePXs4//zzM+0vMjKS4cOHEx8fz/btnpHDO3bsID4+nmHDhvmGa4qISMHw3getZ8+ejBgxgl69enHuuecSGRnJ4sWLfWe93njjjQzb+n/Wr169mk6dOuV6WxGRrOQ0xPErIC9f+5QF2uRhOymhBgwYQHx8PF26dKFKlSqkpKRw5MgRrr/+eh566CG2b9/OXXfdxZ49e4iPj2fv3r088MADDBo0CIAJEyZw/PhxatasydixYwHPhBpTp07l448/Zvbs2ezZs4e4uDjeffddqlevztixY+nTpw8tWrTgnHPO4YEHHvD1tX37dq666ipGjhyZZtmoUaNYsGABgwcP5sILL6Rp06acf/751KxZk/j4eH777TfGjx9Po0aNuPvuu7nzzjupUKGCb5r9ESNGZOhv3LhxREVFce2111KxYkWOHj3KX//6V4YPHw7AkiVLePTRRwEYOnQoo0ePJiIiwjdRSc+ePZk4cSIdOnQovD+YiEgRs3PnTm6//XYSExMBz+RUzjkOHjxIo0aNeOedd+jYsSPgmSzknXfeYcSIEVx00UU0btyYmJgYwPP5ffDgQYYMGcKVV15J9+7dufLKKyldujTjxo3L9bYiIlmxrMZDm1kKUNM5tzfgTs1qArucc8Efl1YMxcbGurVr14Y6DJGgWfnK8Hz30XbAs0GIRCQ8mNk651xsbtsrL0hxE9c3rsD3kRCfUOD7EAmW7PJCdgXUbOB4Hvd5LHV7ERERERERyaUshzg65/rltVPn3CEgz9uLiIiIiIiURBqCKCIiIiIiEiZUoImIiIiIiIQJFWgiIiIiIiJhQgWaiIiIiIhImFCBJiIiIiIiEiZUoImIiIiIiISJLKfZz4yZLUn99YBzrkcBxCMiIiIiIlJiBXoGLQ6oBXwS/FBERERERERKtoDOoAG/A3c459YVRDASZJMtNPsd5gLeZOfOndx+++0kJiYC0LJlS1JSUvj555+JjIxk1KhR3HDDDUEJ78cff6Rfv3589dVXPPLII4wZMyYo/YarW2+9leXLl3PBBReQkJAQ6nBEpBgxC02ecU55Jpwoz4gEV6Bn0HYAyTk1MrNSZlYvTxFJiVSnTh0SEhJo2bIlLVu2JCEhgS+++IL//e9/XHbZZfTo0YMNGzYEZV8NGzYkISGBmjVrBqW/cPfWW29xzTXXhDoMEZGQUp4pOMozIsEVaIH2BnBbLtpFAz8GHo5IWqVKlWLAgAGcOnWKpUuXhjocEREpZpRnRCTcBFqgPQm0NbNnzKxODm3zPO7BzPqa2QEzG5PJuoQsHhHp2jUxs8/M7N9m9k1qzKXTtTEzeyx1/QozW25msZnsM2h9SeBOnToF/DGU5sMPP6Rjx47ExcXRrl07rrrqKtavX59mG+cckydPpnnz5rRr146LL76YPn36sGnTpkz3sWTJEpo0aUL16tWJi4tjy5YtAHzxxRe0bNmSFi1acNVVVzF//nzMjAsuuIDRo0ezevVq4uLiMDOmTJnCgAED6NChAxERESxYsACAL7/8kri4OGJiYmjWrBm9evVi9+7dAGzcuNG3fXx8PAArV66kTZs2mJlvqEj6/QwcOJB27drRqFEj3n333TSvJTk5md69e1O/fn06d+7MyJEjSUlJyfffQUSkuFKeUZ4RCSeBXoO2CU/hdS3wsJkdB/YB6QeDR2SyLEdmVg14E/gOqJZVO+dcXA791ACWAk86514ws0rAl0AlYIhf0yeAO4FLnHPJZnYH8LmZtXDOJQW7LwncsWPHePbZZ6lZsya33norAG+//Ta33XYb9913HwCvvPIKXbt2ZdOmTVSpUgWAJ554gldffZVVq1Zx9tlnc+zYMeLi4vj444+54IILMuznnHPOoWrVqsyfP5+mTZsCsGfPHrp168ajjz7Ko48+inOOe++9F4BHHnmEvn37ApCQkOBLfJ9//jnR0dGMGDGCMmXK8J///IdOnToxffp0/vznP5OSkkKfPn3o2LEj33zzDU2aNPFt79W2bVvefPNNGjZs6Ft26aWX+trNmTOHzz//nGrVqvG3v/2N/v37c/XVV1OpUiUABgwYQFJSEhs2bCAyMpKEhASuv/56YmJigvzXEREp+pRnPJRnRMJHoGfQGgD18RRpBlRMfd4g3ePsPMZTCRjjnPtLHrf3GpIa398BnHNHgcnA/WZWG8DMKgMPA88755JT280B9gMjCqgvyYXExETi4uJo3749DRo0YPXq1bz88suceeaZADz99NMMGDDA1/6OO+5g9+7drFq1CoAjR44wefJk+vXrx9lne96KFStW5Omnn6ZJkyYZ9vfdd9/Ru3dvZs+e7UuaAC+++CKnTp1i6NChgOeb1WHDhmUZ90033UR0dDQAkyZN4tprr2XSpEmcccYZDBw4EPAMpXn88cfZvHkzb7zxRp6Ozw033EC1ap7vL6666ioOHjzo+yZ269atvPvuuwwaNIjIyEgA4uLiaNasWZ72JSJSHCnPZE95RiS0Aj2D5oBL8RQe2TkT+CrQYJxzPwE/BbpdJroBa51zp/2WfYnnzF4XIB7PLQMqkjHOlanbF0Rfkgvei7e91qxZw9VXX80DDzzAuHHjOH78OPfddx+bNm2idOnSvm8Fd+3aBXiGc5w4cYLzzz8/Tb9XXXVVhn15h35UrlyZOnXSjtrdsGEDtWrVomLFir5l/t82plevXsZ5cb7++mvOO++8NN9cnnfeeZQqVYp169bRv3//bI5E5urWrev7PSoqCvAMN/HG7N2Hv4YNG7Jz586A9yUiUhwpz2RPeUYktAI9g5YCbHfObcvugWeCkO3BD9fDzCab2TIz+9LMZpvZhemanAfsSrfM+6lxvl8bsmhX38zKFkBfkgeXXHIJPXv25JlnnuHo0aN06NCBffv28dlnn7Fs2TJfkk0/7XJupn9ev349H3zwAb/88gsPPfRQmnWBTuMcERGR6fK8TEPtvR4ip/14+/bGmpepp0VESjrlmaz3ozwjUvgCKtCcc2Wcc/ty0W6/cy7rr4DyZz2ea8LigCuAbcB6M2vn1yYS+C3ddt7nlfzakE27in7tgtWXj5ndbWZrzWztvn05HtISr3Tp0pw+fZpNmzaxa9cuevToQYUKFQA4efJkmrZNmjShfPnybN68Oc3yZcuW8a9//SvNsl69ehEbG8tLL73EjBkz+Pjjj33rmjVrxu7duzl27Jhv2Y8/BjY5aUxMDN99912ahLZlyxZSUlLSjNWPiori0KFDvuc7duwIaD9e3qEz3qEoXoHGLSKFT3khtJRnckd5RqTgBXoGLYP0sycWNOfcEOfch87jNDAGz5mrx/yaHQHKpdvU+/yoXxuyaXfMr12w+vJ/HTOdc7HOuVjveHLJ3E8//cS7777LFVdcwbnnnktkZCSLFy/2JaP0Y+wjIyMZPnw48fHx/PSTZ8TsoUOHGDx4sO8C5/R69OjBnXfeSf/+/fnll18AGDRoEKVLl+a5554DPN8azpgxI6DYH374YX799VdefvllAFJSUnjqqado1KgRvXr18rWLiYlh2bJlvjazZ88OaD9e5557LrfccgszZszgyBHP2/KLL75g7dq1eepPRAqP8kLoKM/knvKMSMEL9Bo0AMysE3A/cBlQw8waOed+MLO/A1845/J2VWoeOOdSzGwrcI7f4i1A7XRNvc+/92vjXf5TunbbnHMn/doFq6/CNazoDEPYuXMnt99+O4mJiQC+qX6PHz/OoUOHuOGGGxg7dixVq1blnXfeYcSIEVx00UU0btzY9w3hhAkTOHjwIEOGDGHcuHFERUXRtWtXoqKiSElJ4aGHHuLKK6/kwIED3HzzzezZs4f4+HiOHTtG37592bhxI7t376Zt27b8+c9/5qGHHuKjjz5iyJAhzJs3j9q1azN48GCmTZtGmTJlAM+1BYMGDfLt/7333uP999/3va6mTZuyZMkSHnnkEV566SV+++03mjZtytKlS33fzAJMmzaN/v37c/HFF1O/fn3uvPNOZs+ezdChQxk0aBDt2rVLs5/jx48TExPD4MGDARg6dCgjR47kT3/6Ey+//DL33XcfTZo04bzzzuOiiy6iR48eLFy4kLi4OBYtWpRm3wFbOj7v24pIsVKUhrspzxShPCNSwlmgH65mNhEYzh/3OXPA+akF2jvATXgmzhjg8vHJbWYOGOucG+O3rBnQ3Tn3dLq2m4GdzrkrU58/CdwD1PJO7mFmdwKzgHrOuV2pMy/+DDzsnHver68twKfOufuC3VdWYmNjnb55Ck8///wzZ511lu/5zp07qVu3Ll9++SVt27YNYWQhlIsCbeUPv+R7N23POSP7Bh1H5nsfIoXFzNY553J9b0zlhZKjpOSZuL5xBb6PhPiEAt+HSLBklxcCGuJoZjcBDwGbgWHAzcAJ73rn3C14Zi28GeiZ14CzcQYwzMx80yaZWT88k3VM82s3HU/heE9qm4rAX4EXnXO7UmM9DEwA/mJmUantegPRwMQC6kuKmGbNmvHzzz8Dnm+Kp0yZQvPmzbnkkktCHJmIiBQHyjMikl6gQxwHAYuBbs65FAAzS3PreOfcx2Y2BrgXCHioo5m9haewAehrZnHAFOfcB3gmCHkemGtmx4CywEngaufcp34x7DOzK4HpZnY7nsk8FgGj0u3uSTwzUy4zsyN4CrHO/jeWDmZfUvTceuutXHPNNVStWpXjx4/TsGFDPvzwQ0qXztPoYBERkTSUZ0QkvUD/9V8M3OQtzrLxMZ4bNwfMOXdrNut+BUanPnLqZwPQKYc2Dngq9VEofUnR8uKLL4Y6BBERKcaUZ0QkvUBncawE7M5Fu9+BqMDDERERERERKbkCLdB2AB1y0a4bBXijahERERERkeIo0ALtQ2Cymd2QVYPUdU8B72fVRkRERERERDIK9Bq0Z4DbgHfN7EdgLVAGGG1mpYFL8dyPbCeavVBERERERCQgARVoqTMadgLeBprwx82h7+CP+6JtAHo45w4ELUoREREREZESIOA5XJ1zm8ysOXAj0AWol7pqO54p+BfkYpZHESmignETahERERHJXJ5uspFagL2b+hARCbqcCsG2HQspEBEREZFCFOgkISIiIiIiIlJA8lSgmVkLM/s/M9tsZkfN7Ejq7zPNrGWQYxQRERERESkRAi7QzGwkntkb+wPnAxWAiqm/DwTWmNkjwQxSRERERESkJAjoGjQz+xPwNHAIz0yO64B9eGZwjAZigFuAp83sB+fc/OCGKyIiIiIiUnwFOknIMDxFWVfn3P7MGqSePVsEDAdUoImIiIiIiORSoAXaRWRTnIHvXmnDgY/yFZmIiIiIiEgJE+g1aL8BP+ai3VbgeODhiIiIiIiIlFyBFmhrgBa5aNcS+NJ/gZmVN7O7AtyfiIiIiIhIiRFogfY0MNnMmmTVwMyaAk8Bj6VbFQXMCnB/IiIiIiIiJUag16DFAXuBb83sC+B/qc8BzgQuBNrjmeHxJjO7yW/byPyFKiIiIiLhZsyYMaEOQaRYCbRAGwM4PNPqd0h9ZKZH6sNSn3u3cYGHKCIiIiIiUjIEWqABTAGO5GG7ysCDedhORERERESkRMhLgfY359zenJulZWY1gb/mYX8iIiIiIiIlQqCThPQDDuZxX8mp24uIiIiIiEgmAjqD5pybndcdOedOAHneXkREREREpLgL9AyaiIiIiIiIFBAVaCIiIiIiImFCBZqIiIiIiEiYUIEmIiIiIiISJlSgiYiIiIiIhAkVaCIiIiIiImFCBZqIiIiIiEiYCKhAM7PSZtY+9VHLb3ldM5tjZv81s4/M7NLghyoiIiIiIlK8BXoG7RogAVgCXA1gZuWBT4BeQBOgK7DEzM4LXpgiIiIiIiLFX6AF2m1AIlDPORefuqwXcCHwHdAeuBLYCTwUnBBFRERERERKhtIBto8FHnTO7fJb1gdwwP3OuRUAZvYwMCE4IYqIiIiIiJQMgZ5Bqw/8z/vEzKoDlwNJzrklfu3WA3XzH56IiIiIiEjJEWiBlgyc4ff8T0AEMD9duwrAkbyHJSIiIiIiUvIEWqD9F3gAwMzOBB7BM7zxn+nadQC25zs6ERERERGREiTQAm0K0M/MkoFtwNnAx865jQBmVtvM+gJP4pntUURERERERHIpoALNOfcJcB+eoY6ngY+Afn5NngZeBaoDbwYnRBERERERkZIh0Fkccc79A/hHFuv6kbZgExERERERkVwKdIhjtsysopnda2ZNgtmviIiIiIhISRBQgWZmp1MnB8lKZWAGsN7Mbs9XZCIiIiIiIiVMoEMcLbuVzrmfU++N9jDwKDA3r4GJiIiISPhLSEoIdQgAjBkzJihtREItqEMcAZxzycBMoEGw+xYRERERESnOsj2DZmb1yFhotTWzX7PZrBJwG7Avf6GJiIiIiIiULDkNcewHjEq37N1c9j058HBERERERERKrpwKtCTgC7/n7YGvgJNZtE/Bc4+0L/BMFiIiIiIiIiK5lG2B5pybDcz2PjezFOAm59zegg5MRERERESkpAl0kpCxwJGCCERERERERKSkC6hAc86Ndc4dy6mdmZUxs/Z5DcrM+prZATMbk8k6M7PHzOwbM1thZsvNLDaTdk3M7DMz+3dq22fMrHSo+xIREREREclK0KfZT1UdWBroRmZWzcw+AWKAalk0ewLoC3R0zrUD/gF8bmYN/Pqpkbr/Bc65y4F2wLVknLikUPsSERERERHJTp4KNDO73MwGpZ4xGpX+AQzLYzyVgDHOub9ksd/KeG6C/Xzq/dZwzs0B9gMj/JoOwXNT7b+ntjmKp6C638xqh7AvERERERGRLOU0i2MaqQXJR0Bz/8XpmrnUZS7QYJxzPwE/ZdMkDqiIZyZJfyuBbn7PuwFrnXOn/ZZ9CUQAXYD4EPUlIiIiIiKSpYAKNOA5oAWwDlgN/Ar8nkm7ysCD+Yosc+el/tyVbvlOoL6ZlXXOnUxt900mbQDOD2FfIiIiIiIiWQq0QOsMTHDOPZpdIzOrCfw1z1FlLTL152/plnufV8Rzj7bIbNpUCmFfPmZ2N3A3QL169RARkZJNeUFERCDwa9DK4HdftGz8AnQMPJwceaf4L5duuff5Mb92WbU5GsK+fJxzM51zsc652Ojo6PSrRUSkhFFeEBERCLxA+xrP2aCcnAZ+DDycHG1J/Vk73fLawDa/YYRbsmgD8H0I+xIREREREclSoAXaKGCsmaU/U5ReNAVToCUAx4HW6Za3BRb5PV8IxJpZhN+yy/AUjotD2JeIiIiIiEiWAr0GrT6eqeN3mNlbwFY8wxnTz9gYFYTYMnDOHTazCcBfzOw159xBM+uNpyCc6Nd0Op5x/PcAM8ysIp5r4l50zu0KYV8i4W3p+FBHICIiIlKiBVqgxfPHNPr3ZtMuT9PsA6QWft7B933NLA6Y4pz7IHXZk0AKsMzMjqTup7NzLsnbh3Nun5ldCUw3s9vxTOaxCM8ZQH+F2peIBFFuismOIws+DhEREZEgCrRAA3gLz3C+7FQEeuShb5xzt+aw3gFPpT6ya7cB6BRufYmIiIiIiGQlLwXaYOfc3uwapE6zn22hJSIiIiIiImkFOknIE8DhXLRLBvoFHI2IiIiIiEgJFtAZNOfc07lsd4Lc3S9NREREREREUgV6Bs3HzJqb2b1m9qSZVU9d1iJ4oYmIiIiIiJQsAV+DZmbn4pnN8TK/xbOAA0C8mVUAbnPO/ScoEYqIiIiIiJQQAZ1BM7Mz8dyU+XLgIPAfPFPLe40A9uGZar5+kGIUEREREREpEQId4jgSqArcDtRwzrUCTnhXOuc+BeKA1cDDwQlRRERERESkZAi0QLsWGOGce8M5l5JZA+fcaWAC0DG/wYmIiIiIiJQkgRZoZwNLctFuK1Av8HBERERERERKrkALtOPAGbloVy+1rYiIiIiIiORSoLM4rsNzHdr1WTUws1LA48CafMQlIiIiIpJrCUkJoQ5BJCgCLdBeBN41s3XAVGBt6vKqZnY+cCkwBIghmyJOREREREREMgqoQHPOLTCzqcCDwGy/Vf5nywyY7JxbGIT4RERERERESoxAr0HDOTcM6A1sxFOM+T82AL2ccw8FM0gREREREZGSINAhjgA4594E3jSzswDvDam3O+f2BC0yERERERGREiagAs3MRgHPOueOATjnfgZ+LojARERERERESppAhziOxnMvNBEREREREQmyQAs0A/5jZgvM7HoziyiIoEREREREREqigCcJAXoAe4F/Aj+Z2SQzaxzcsEREREREREqeQAu0ZcBy59zdQC3gYSAW2GhmX5rZADOLDHaQIiIiIiIiJUGg90Hr6Pf7ceA14DUzOwfoB4wCnjOzt4FXnXPLgxmsiBSslT/8EuoQREREREq0PE2zn55z7gczGw9sAyYAd6U+dI2aiBSI3BSTbTvm2EREREQkrAQ0xNHM7jKzcumWXWZmrwB7gH8A1YFfgeeDFqWIiIiIiEgJEOgZtFnAIjMrBfTBM6yxEZ7ZHVOAT4FXgQXOuZPBDFRERERERKS4C7RAM+BN4Ao8wxcNSALigVnOuR3BDE5ERERERKQkycs1aB2BE8DbwCvOuc+DG5KIiIiIiEjJlJcC7SE8hVlykGMREREREREp0QK9D9o2IF7FmYiIiIiISPAFeh+0hgUViIiIiIiISEmXbYFmZvW8vzvntufQtgzQy3+Zc+61fEUnIiIiIiJSguR0Bi0JcABmFu2cO5BN24p4ZnP0coAKNBERERERkVzKzRDHHsAB4GB2jZxzB0m9ps3MmgLr8x2diIiIiIhICZKbAu3fzrm9AGaWQuoZNS/nXEQm27hMlomIiIiIiEg2Ap1mvz+e4suAvwOjgh6RiIiIiIhICRXoLI7x3t/N7HngnWAHJCIiIiLhYcyYMaEOQaTECfQ+aCIiIiIiIlJAVKCJiIiIiIiECRVoIiIiIiIiYSI316DdZmaHMlkeAdxkZvsyWVc3f2GJiIiIiIiUPLkp0KZlsdyASUGMRUREREREpETLTYH2FXAywH4rATGBhyMiIiIiIlJy5aZAu8l7o+rcMrOmwPq8hSQiIiIiIlIy5TRJyDrg9zz0ewz4Og/biYiIiIiIlFjZnkFzzl2Sl06dcz8AedpWRERERESkpNI0+yIiIiIiImFCBZqIiIiIiEiYUIEmIiIiIiISJlSgiYiIiIiIhIkiV6CZWZyZJZlZQrrHAL82ZmaPmdk3ZrbCzJabWWwmfTUxs8/M7N+pbZ8xs9Lp2gStLxERERERkewU1QIi3jk3Jpv1TwB3Apc455LN7A7gczNr4ZxLAjCzGsBS4Enn3AtmVgn4Es9NtocUUF8iIiIiIiJZKqoFWpbMrDLwMDDSOZcM4JybY2ZjgRHAoNSmQwAD/p7a5qiZTQZeNbOJzrldweyroF+3SK4sHR/qCEREREJmzJgxQWkjUpCKXYEGxAEVga/SLV8JdPN73g1Y65w77bfsSyAC6ALEB7kvESlsuSlIO44s+DhEREREcqnIXYOWqo2ZLUq9HuxTM/uL3/Ve56X+TH/WaidQ38zK+rXLrA3A+QXQl4iIiIiISLaK4hm0g8BPwAjn3AEzawwsAq4BrgUiU9v9lm477/OKwMnUdlm1qZT6M5h9iYiIiIiIZKvInUFzzn3jnBvonDuQ+nwz8BTQzcxaA0dSm5ZLt6n3+bHUn0eyaXPUr02w+krDzO42s7Vmtnbfvn2ZNRERkRJEeUFERKAIFmhZ+D715znAltTfa6drUxvY5pw7mfp8SxZt/PsLZl9pOOdmOudinXOx0dHRmTUREZESRHlBRESgCBZoZjbezBqmW1w39edOIAE4DrRO16YtnqGQXguBWDOL8Ft2GXAaWJz6PJh9iYiIiIiIZKvIFWh4iqOhZlYKwMyqAw8Ba4EVzrnDwATgL2YWldqmNxANTPTrZzrggHtS21QE/gq86J0WP5h9iYiIiIiI5KQoThLyDHAvsNLMTuCZhONz4GnnXEpqmyeBFGCZmR3BUzx19t5YGsA5t8/MrgSmm9ntqf0sAkal218w+xIREREREclSkSvQnHOLyWHYoHPO4Zk45Kkc2m0AOhVWXyIiIiIiItkpikMcRUREREREiiUVaCIiIiIiImFCBZqIiIiIiEiYUIEmIiIiIiISJlSgiYiIiIiIhAkVaCIiIiIiImFCBZqIiIiIiEiYUIEmIiIiIiISJlSgiYiIiIiIhInSoQ5ARERERMJTQlJCqEMQKXF0Bk1ERERERCRMqEATEREREREJEyrQREREREREwoQKNBERERERkTChAk1ERERERCRMaBZHkRJk5Q+/hDqEQpWb19u2YyEEIiIiIpJLOoMmIiIiIiISJlSgiYiIiIiIhAkNcRQREREpocaMGRPqEEQkHZ1BExERERERCRMq0ERERERERMKECjQREREREZEwoWvQRIqLpeNDHUHRlNNx6ziycOIQERERQQWaiIiIiJQQCUkJoQ5BJEca4igiIiIiIhImVKCJiIiIiIiECQ1xFBERERFJldO94XTvOCloOoMmIiIiIiISJlSgiYiIiIiIhAkVaCIiIiIiImFCBZqIiIiIiEiYUIEmIiIiIiISJlSgiYiIiIiIhAkVaCIiIiIiImFCBZqIiIiIiEiYUIEmIiIiIiISJkqHOgARKX7aJk/Odx8rqw4LQiQiIiXXmDFjQh2Cz7LZy/LdR4c+HYIQiUj4U4EmUlQsHR/qCIDgFF/B2E+hFXC5Oe4dRxZ8HCIiYSoYxVcw9qMCTooLFWgi4lNYxVcw5CZWnYUTEcmfwiq+giE3saqIk6JABZpICVKUCjARESl4Y8eODXUIIpKOCjQRKbZyV5A+U+BxiIhIeMjNWba40XHZrs/NtX3hdP2fFD0q0ESKi68fDXUERVNOx+1iFXAiUjTp7Fje5HTcRo8eXUiRSEmlAk1ERESkCNJZGpHiyZxzoY6hxIuNjXVr164NdRgS7iZbqCOQrAzT56hkz8zWOedic9teeUFyw0x5IVzp/9eSk+zygs6giYSDMJlCX/Iop7+fpuEXERGRXFKBJhIOdP1Y0ZbT308FmogESGfHirac/n46wybZKRXqAERERERERMRDZ9BECpquHZPcvAd0HZtIiaIzZCVbbv7+OstWcukMmoiIiIiISJjQGbQgMrMmwHSgAlARWASMcs6dCmlgUrB0hkyCIaf3kc6wiRQZOjsmwaCzbCWXCrQgMbMawFLgSefcC2ZWCfgSqAQMCWlwkncqviRcaJikSFhQ8SXhRJORFE8q0IJnCGDA3wGcc0fNbDLwqplNdM7tCml0kjkVYFKcqIgTyTcVYFKc6Cxc0aQCLXi6AWudc6f9ln0JRABdgPhQBFWsqbgSCVww/t2oyJMwpeJKJHDB+HejIi+4VKAFz3nAN+mW7Uz9eX4hxxJaKpxEirfC+jeuQrDYUOEkUrwV1r/xklIIqkALnkjgt3TLvM8rpW9sZncDd6c+PWJmmwswttyoAewPcQxFkY5b3ui45U3JOm7Dg5bww+G41c+pgfJCsaHjljc6bnlToo5bEAvBcDhuWeYFFWjBcwQol26Z9/nR9I2dczOBmQUdVG6Z2VrnXGyo4yhqdNzyRsctb3Tc8qaoHDflheJBxy1vdNzyRsctb8L9uOk+aMGzBaidbpn3+feFHIuIiIiIiBRBKtCCZyEQa2YRfssuA04Di0MTkoiIiIiIFCUq0IJnOuCAewDMrCLwV+DFIjLFftgMqylidNzyRsctb3Tc8kbHLW903PJGxy1vdNzyRsctb8L6uFlJmQ2lMJjZRXgKtfJ4JgZZBIxyzv0e0sBERERERKRIUIEmIiIiIiISJjTEUTCzamb2qpk5M2uQRZu6Zvaema0ys6/N7CUziyzkUMOamcWb2VdmlpDuUSfUsYUDM2tiZp+Z2b/N7Bsze8bMNJNsDswszsySMnlfDQh1bOHIzPqa2QEzG5PJOjOzx1LffyvMbLmZhe0sXqGkvBAcygvZU17IG+WFwBTFvKB/BCWcmXUGngU2ZdOmHPAp8JFz7qbUD88PgbnADYUSaNHR0zmXFOogwo2Z1QCWAk86514ws0rAl3iGAg8JaXBFQ7xzbkyogwhnZlYNeBP4DqiWRbMngDuBS5xzyWZ2B/C5mbXQv9s/KC8EnfJCJpQX8k15IQdFOS/oDJoAdAQ+zmb9HcD5wDMAzrlTqb93N7NLCz48KQaGAAb8HcA5dxSYDNxvZulvTyGSF5WAMc65v2S20swqAw8DzzvnkgGcc3Pw3Kh0RGEFWYQoL0hBU16QglZk84IKtBLOOfeZc+7XHJp1A75zzh3wW/YVkJK6TiQn3YC1zrnTfsu+BCKALqEJSYoT59xPzrmV2TSJAyri+ezytxJ9jqWhvCCFRHlBClRRzgsa4ii5cR6Q5lYBzrmTZrYfzzeo8ocRqbN5lgZ2AlOcc+n/4ZdE5wHfpFu2M/Wn3kM5a2Nmi4BI4ATwAfD31LMWkjvnpf5Mf9uTnUB9MyvrnDtZyDEVZcoLuae8kDnlhfxRXsi/sM0LKtCKGTOLAmrl1M45l+W1BZmIBH7KZPlveE4fF0t5OJbfAbuBv+D5FnkA8KWZ9XLOzSuwQIuGSDzvF3/e58X2PRQkB/H8+xvhnDtgZo3x3MLjGuDakEZWtHgnr8jqfVgRKJYFmvJC8CgvBJXyQt4pLwRH2OYFFWjFz63A/+WinQXQ5xGgXCbLywFHA+inqAnoWDrnnkm3/GUzuwsYA5T0RJzZe8j7vDi/h/LNOfcNMNDv+WYzewp4xcxaO+dWhS66IuVI6s+s3ofHCjGWwqa8EDzKC8GjvJBHygtBE7Z5QdegFTPOuZedc5bTI8ButwBpLtg1s7JADeD7YMUeboJ0LL8HzimMeMNchveQ3/Ni+x4qQN5jpvdW7m1J/ZnZ+3BbcR7eqLwQPMoLQaW8EFzKC4EL27ygAk1yYyHQKHW6Uq/WeN4/i0ITUngxszPNbFomq+ryx5j6kmwhEGtmEX7LLgNOA4tDE1LRYGbjzaxhusV1U3/qvZV7CcBxPJ9d/tqiz7G8UF7IgfJCjpQX8kh5IWgSCNO8oAJNcmMOnm9mRgKkfpiOBP6l0+g+FYH7zKytd4GZdQI6A1NDFlX4mA444B4AM6sI/BV40TmX/uJcSastMNTMSgGYWXXgIWAtsCKUgRUlzrnDwATgL6nXEWFmvYFoYGIoYyuilBdypryQPeWFvFNeCIJwzgvmnAvl/iXEzCwGz31HagKNgVV4ZgPq4n9q18zqAs/jOe1bFlgNDHPOHcnQaQlkZuWBwcBNeC4uLY3nC5BpuhDcI3UWs+lAeTwXgC8CRjnnfg9pYGHOzLoA9wJ18PzbrITn5q5Pe+/bIh5m9haexNoB2AYk4Zkx74PU9QY8BvTAc+2BA/7qnFsTkoDDlPJCcCgv5Ex5IW+UF3KvqOYFFWgiIiIiIiJhQkMcRUREREREwoQKNBERERERkTChAk1ERERERCRMqEATEREREREJEyrQREREREREwoQKNBERERERkTChAk1ERERERCRMqEATEREREREJEyrQREREREREwoQKNBERERERkTChAk1ERERERCRMqEATkQJlZs+YmTOzTzNZZ2Y2N3X9QjMrE4oYRUSk8CgviGTPnHOhjkFEijEzqwxsAc4ErnLOfea37gXgfmA5cLVz7nhoohQRkcKivCCSPZ1BE5EC5Zw7DIxNfTreu9zMxuFJwuuA65SERURKBuUFkezpDJqIFDgzKw18C1wA3ArUAZ4D/ge0d87tD110IiJS2JQXRLKmAk1ECoWZdQfeB/YDZwDbgHbOuZ0hDUxEREJCeUEkcyrQRKTQmNl/gYuAvcBlzrmtIQ5JRERCSHlBJCNdgyYihcLMBuNJwgDlgUMhDEdEREJMeUEkcyrQRKTAmVkfPNcW7AT+BVQBRocyJhERCR3lBZGsaYijiBQoM7sJeAtIBq4AjgDfAaWBi5xz34UuOhERKWzKCyLZ0xk0ESkwZtYZeAM4BlzjnPufc24H8AKeRDwhlPGJiEjhUl4QyZnOoIlIgTCzNsBneBJuV+fcUr911YEfgCjgCufcitBEKSIihUV5QSR3dAZNRILOzJoBC4FywJ/8kzCAc+4AMDH16bOFHJ6IiBQy5QWR3NMZNBERERERkTChM2giIiIiIiJhQgWaiIiIiIhImFCBJiIiIiIiEiZUoImIiIiIiIQJFWgiIiIiIiJhQgWaiIiIiIhImFCBJiIiIiIiEiZUoImIiIiIiIQJFWgiIiIiIiJhQgWaiIiIiIhImFCBJiIiIiIiEib+HysEwDGvJ82NAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 864x360 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "bins = np.linspace(-11, 11, 41)\n",
    "\n",
    "fig, ax = plt.subplots(1,\n",
    "                       2,\n",
    "                       figsize=(12, 5),\n",
    "                       constrained_layout=True,\n",
    "                       sharey=True)\n",
    "\n",
    "ax[0].set_xlabel(r'$x$')\n",
    "ax[0].set_ylabel(r'Events per bin')\n",
    "ax[0].hist(theta0_G[theta0_G!=dummyval], bins=bins, **plot_style_2, label='Generation')\n",
    "ax[0].hist(theta0_S_withback[theta0_S_withback!=dummyval], bins=bins, **plot_style_2, label='Simulation')\n",
    "ax[0].hist(theta0_S_withback[theta0_G_withback==-dummyval], bins=bins, color=\"darkorange\", label='Background')\n",
    "legend = ax[0].legend(\n",
    "    title=r'Synthetic''\\n''($\\mu$, $\\sigma$) = {}'.format(theta0_param),\n",
    "    loc='upper left',\n",
    "    frameon=False)\n",
    "plt.setp(legend.get_title(), multialignment='center')\n",
    "\n",
    "ax[1].set_xlabel(r'$x$')\n",
    "ax[1].hist(theta_unknown_G[theta_unknown_G!=dummyval], bins=bins, **plot_style_2, label='Truth',color=\"green\")\n",
    "ax[1].hist(theta_unknown_S_withback[theta_unknown_S_withback!=dummyval], bins=bins, **plot_style_2, label='Data',color=\"black\")\n",
    "ax[1].hist(theta_unknown_S_withback[theta_unknown_G_withback==-dummyval], bins=bins, label='Background',color=\"black\")\n",
    "legend = ax[1].legend(\n",
    "    title=r'Natural''\\n''($\\mu$, $\\sigma$) = {}'.format(theta_unknown_param),\n",
    "    loc='upper left',\n",
    "    frameon=False)\n",
    "plt.setp(legend.get_title(), multialignment='center')\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Unfold Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-17T03:49:29.597528Z",
     "start_time": "2020-11-17T03:49:29.594288Z"
    }
   },
   "outputs": [],
   "source": [
    "iterations = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-17T03:49:29.688675Z",
     "start_time": "2020-11-17T03:49:29.599367Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-01-26 20:13:01.025923: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-01-26 20:13:01.026252: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-01-26 20:13:01.026429: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-01-26 20:13:01.026589: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-01-26 20:13:01.026748: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-01-26 20:13:01.026908: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-01-26 20:13:01.601575: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-01-26 20:13:01.601801: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-01-26 20:13:01.601977: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-01-26 20:13:01.602144: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-01-26 20:13:01.602311: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-01-26 20:13:01.602460: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1613] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 1024 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3090, pci bus id: 0000:41:00.0, compute capability: 8.6\n",
      "2023-01-26 20:13:01.602746: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-01-26 20:13:01.602887: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1613] Created device /job:localhost/replica:0/task:0/device:GPU:1 with 22263 MB memory:  -> device: 1, name: NVIDIA GeForce RTX 3090, pci bus id: 0000:61:00.0, compute capability: 8.6\n"
     ]
    }
   ],
   "source": [
    "xvals_1 = np.concatenate((theta0_S, theta_unknown_S)) #synthetic, measured.\n",
    "yvals_1 = np.concatenate((labels0, labels_unknown)) \n",
    "#QUESTION: At what point are theses mixed? Avoid [0,0,0...0,1,1...1,1,1]\n",
    "#I think at test_train_split function\n",
    "\n",
    "xvals_2 = np.concatenate((theta0_G, theta0_G)) \n",
    "#QUESTION whay 0_G twice? Because theta_unknown_G is ultimate target (particle level – nature), \n",
    "#and can't be used as an input to the training.\n",
    "yvals_2 = np.concatenate((labels0, labels_unknown))\n",
    "\n",
    "weights = np.empty(shape=(iterations, 2, len(theta0)))\n",
    "# shape = (iteration, step, event)\n",
    "\n",
    "\n",
    "nn_output = np.zeros( shape=(iterations, 2, len(theta0)))\n",
    "\n",
    "inputs = Input((1, ))\n",
    "hidden_layer_1 = Dense(50, activation='relu')(inputs)\n",
    "hidden_layer_2 = Dense(50, activation='relu')(hidden_layer_1)\n",
    "hidden_layer_3 = Dense(50, activation='relu')(hidden_layer_2)\n",
    "outputs = Dense(1, activation='sigmoid')(hidden_layer_3)\n",
    "\n",
    "model = Model(inputs=inputs, outputs=outputs)\n",
    "\n",
    "#earlystopping = EarlyStopping(patience=10,\n",
    "#                              verbose=1,\n",
    "#                              restore_best_weights=True)\n",
    "\n",
    "earlystopping = EarlyStopping(patience=patience_setval,\n",
    "                              verbose=1,\n",
    "                              restore_best_weights=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 1.63726592,  0.64124504, -0.41135563, ...,  0.20327187,\n",
       "        0.93358888,  0.59839889])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xvals_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2000000,)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xvals_1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 0., 0., ..., 1., 1., 1.])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "yvals_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2000000,)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "yvals_1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-17T03:49:29.695163Z",
     "start_time": "2020-11-17T03:49:29.690659Z"
    }
   },
   "outputs": [],
   "source": [
    "# from NN (DCTR)\n",
    "def reweight(events):\n",
    "    f = model.predict(events, batch_size=10000)\n",
    "    weights = f / (1. - f)\n",
    "    return np.squeeze(np.nan_to_num(weights)) \n",
    "#Question: how is the model passed? Stored in memory before function is called?\n",
    "#QUESTION: is this p(w,X)/p(w',X'), where p is PDF of (x)?\n",
    "#reweights sim to data, then "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 124 ms, sys: 8.19 ms, total: 132 ms\n",
      "Wall time: 132 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "#We can do the background subtraction as part of the iterative unfolding, but it is easier to do it first.\n",
    "\n",
    "\n",
    "    \n",
    "x_data_and_MCback = np.concatenate([theta0_S_withback[theta0_G_withback==-dummyval],\n",
    "                                    theta_unknown_S_withback[theta_unknown_S_withback!=dummyval],\n",
    "                                    theta_unknown_S_withback[theta_unknown_S_withback!=dummyval]])\n",
    "    \n",
    "y_data_and_MCback = np.concatenate([np.ones(len(theta0_S_withback[theta0_G_withback==-dummyval])),\n",
    "                                    np.ones(len(theta_unknown_S_withback[theta_unknown_S_withback!=dummyval])),\n",
    "                                    np.zeros(len(theta_unknown_S_withback[theta_unknown_S_withback!=dummyval]))])\n",
    "    \n",
    "W_data_and_MCback = np.concatenate([-1.*np.ones(len(theta0_S_withback[theta0_G_withback==-dummyval])),\n",
    "                                    np.ones(len(theta_unknown_S_withback[theta_unknown_S_withback!=dummyval])),\n",
    "                                    np.ones(len(theta_unknown_S_withback[theta_unknown_S_withback!=dummyval]))])\n",
    "\n",
    "X_train_1, X_test_1, Y_train_1, Y_test_1, w_train_1, w_test_1 = train_test_split(\n",
    "    x_data_and_MCback, y_data_and_MCback, W_data_and_MCback)\n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Owen's notes\n",
    "\n",
    "See my more detailed notes in this file on my laptop: /Users/owen/work/eic/omnifold/2023-01-23-notes.docx\n",
    "\n",
    "Here's a summary of how the BG subtraction works.  \n",
    "\n",
    "- The NN is given a binary classification task where the two categories are signal-only (y=1, call this a) and signal plus background (y=0, call this b).\n",
    "\n",
    "- The signal-only sample is constructed by combining the \"data\" (theta_unknown_S_withback[theta_unknown_S_withback!=dummyval]) with a BG sample (theta0_S_withback[theta0_G_withback==-dummyval]), where the data weight is +1 and the BG weight is -1.  This does the BG subtraction in the loss function because the sum of the BG sample, with weight -1, will cancel the sum of the BG component of the data.\n",
    "\n",
    "- The NN output f is an estimation of the probability that an event is in the class a and this is approximately a/(a+b).\n",
    "\n",
    "- The signal fraction is given by a/b.  To get this from f, it's Fr(sig) = f/(1-f) = a/b, which is also the likelihood ratio or the ratio of the probabilities of the two classes.\n",
    "\n",
    "This BG subtraction trick is to cancel it in the loss function by adding it to the signal+bg sample with a negative weight.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "#model.compile(loss='binary_crossentropy',\n",
    "#              optimizer='Adam',\n",
    "#              metrics=['accuracy'])\n",
    "\n",
    "#model.compile(loss='binary_crossentropy',\n",
    "#              optimizer='Adam',\n",
    "#              metrics=['accuracy'],\n",
    "#              weighted_metrics=[])\n",
    "\n",
    "\n",
    "#training_hist = model.fit(X_train_1,\n",
    "#          Y_train_1,\n",
    "#          sample_weight=w_train_1,\n",
    "#          epochs=200,\n",
    "#          batch_size=10000,\n",
    "#          validation_data=(X_test_1, Y_test_1, w_test_1),\n",
    "#          callbacks=[earlystopping],\n",
    "#          verbose=1)\n",
    "\n",
    "the_optimizer = tf.keras.optimizers.Adam( learning_rate=learning_rate_setval )\n",
    "\n",
    "model.compile(loss='binary_crossentropy',\n",
    "              optimizer=the_optimizer,\n",
    "              metrics=['accuracy'],\n",
    "              weighted_metrics=[])\n",
    "\n",
    "\n",
    "training_hist = model.fit(X_train_1,\n",
    "          Y_train_1,\n",
    "          sample_weight=w_train_1,\n",
    "          epochs=100,\n",
    "          batch_size=batch_size_setval,\n",
    "          validation_data=(X_test_1, Y_test_1, w_test_1),\n",
    "          callbacks=[earlystopping],\n",
    "          verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot( training_hist.history['loss'])\n",
    "plt.plot( training_hist.history['val_loss'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "w_data = reweight(theta_unknown_S_withback[theta_unknown_S_withback!=dummyval])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "w_data_bgsub_only = w_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "i=0\n",
    "bins = np.linspace(-11, 11, 41)\n",
    "\n",
    "fig, ax = plt.subplots(1,\n",
    "                       2,\n",
    "                       figsize=(12, 5),\n",
    "                       constrained_layout=True,\n",
    "                       sharey=True)\n",
    "\n",
    "ax[0].set_xlabel(r'$x$')\n",
    "ax[0].set_ylabel('Events per bin')\n",
    "ax[0].hist(theta0_G[theta0_G!=dummyval], bins=bins, **plot_style_2, label='Generation')\n",
    "ax[0].hist(theta0_S[theta0_S!=dummyval], bins=bins, **plot_style_2, label='Simulation (no back.)')\n",
    "legend = ax[0].legend(\n",
    "    title='Synthetic\\n($\\mu$, $\\sigma$) = {}'.format(theta0_param),\n",
    "    loc='upper left',\n",
    "    frameon=False)\n",
    "plt.setp(legend.get_title(), multialignment='center')\n",
    "\n",
    "ax[1].set_xlabel('$x$')\n",
    "#ax[1].hist(theta_unknown_G[theta_unknown_G!=dummyval], bins=bins, **plot_style_2, label='Truth',color=\"green\")\n",
    "ax[1].hist(theta_unknown_S[theta_unknown_S!=dummyval], bins=bins, **plot_style_2, label='Data (no back.)',color=\"black\")\n",
    "ax[1].hist(theta_unknown_S_withback[theta_unknown_S_withback!=dummyval], bins=bins, histtype=\"step\", label='Data (reweighted)',color=\"black\",weights=w_data)\n",
    "legend = ax[1].legend(\n",
    "    title='Natural\\n($\\mu$, $\\sigma$) = {}'.format(theta_unknown_param),\n",
    "    loc='upper left',\n",
    "    frameon=False)\n",
    "plt.setp(legend.get_title(), multialignment='center')\n",
    "\n",
    "fig.show()\n",
    "plt.savefig(\"plot_\"+str(i)+\"_datareweight.pdf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_output_bgsub = model.predict(theta_unknown_S_withback[theta_unknown_S_withback!=dummyval], batch_size=10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_output_bgsub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_output_bgsub.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "squeezed_model_output = np.squeeze(model_output_bgsub)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "squeezed_model_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "squeezed_model_output.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig,ax = plt.subplots(2,2,figsize=(20,20))\n",
    "\n",
    "\n",
    "\n",
    "ax[0][0].hist( theta_unknown_S_withback[theta_unknown_S_withback!=dummyval], range=[-10,10], bins=50, alpha=0.8)\n",
    "ax[0][0].hist( theta_unknown_S[theta_unknown_S!=dummyval], range=[-10,10], bins=50, alpha=0.8)\n",
    "ax[0][0].hist( theta_background, range=[-10,10], bins=50, histtype=\"step\")\n",
    "\n",
    "ax[0][1].hist( squeezed_model_output, bins=90 )\n",
    "\n",
    "\n",
    "ax[1][0].hist2d(theta_unknown_S_withback[theta_unknown_S_withback!=dummyval],\n",
    "         squeezed_model_output,\n",
    "         density=True,\n",
    "         bins=200,\n",
    "         range=([-10,10],[-0.1,1]),\n",
    "         norm=mpl.colors.LogNorm())\n",
    "ax[1][0].grid()\n",
    "\n",
    "ax[1][1].hist2d(theta_unknown_S_withback[theta_unknown_S_withback!=dummyval],\n",
    "         w_data,\n",
    "         density=True,\n",
    "         bins=200,\n",
    "         range=([-10,10],[-0.1,1]),\n",
    "         norm=mpl.colors.LogNorm())\n",
    "ax[1][1].grid()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hist_data_all = plt.hist( theta_unknown_S_withback[theta_unknown_S_withback!=dummyval], range=[-10,10], bins=50 )\n",
    "hist_data_signal = plt.hist( theta_unknown_S[theta_unknown_S!=dummyval], range=[-10,10], bins=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hist_data_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hist_data_all[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hist_axis = hist_data_all[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hist_axis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hist_axis_centers = np.ones(50)\n",
    "for i in range(0,50):\n",
    "    hist_axis_centers[i] = 0.5*(hist_axis[i]+hist_axis[i+1])\n",
    "    #print(i, hist_axis_centers[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "signal_frac = (hist_data_signal[0])/(hist_data_all[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "signal_frac"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig,ax = plt.subplots(1,2,figsize=(20,10))\n",
    "\n",
    "\n",
    "ax[0].plot(hist_axis_centers,signal_frac)\n",
    "ax[0].set_ylim(-0.1,1)\n",
    "ax[0].set_xlim(-10,10)\n",
    "ax[0].grid()\n",
    "\n",
    "ax[1].hist2d(theta_unknown_S_withback[theta_unknown_S_withback!=dummyval],\n",
    "         w_data_bgsub_only,\n",
    "         density=True,\n",
    "         bins=250,\n",
    "         range=([-10,10],[-0.1,1]),\n",
    "         norm=mpl.colors.LogNorm())\n",
    "ax[1].grid()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "of_training_history = np.zeros(shape=(4,2,1000))\n",
    "of_training_history_val = np.zeros(shape=(4,2,1000))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## OmniFold part starts here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initial iterative weights are ones\n",
    "weights_pull = np.ones(len(theta0_S))\n",
    "weights_push = np.ones(len(theta0_S))\n",
    "\n",
    "#-- owen: adding this\n",
    "weights_push_last_iteration = np.ones(len(theta0_S))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xvals_1 = np.concatenate((theta0_S, theta_unknown_S_withback[theta_unknown_S_withback!=dummyval]))\n",
    "yvals_1 = np.concatenate((labels0, np.ones(len(theta_unknown_S_withback[theta_unknown_S_withback!=dummyval]))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-17T04:28:20.621248Z",
     "start_time": "2020-11-17T03:49:29.711813Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "for i in range(iterations):\n",
    "    print(\"\\n\\n\\nITERATION: {}\\n\".format(i + 1))\n",
    "\n",
    "    \n",
    "    \n",
    "    \n",
    "    weights_push_last_iteration = weights_push\n",
    "    \n",
    "    \n",
    "    # STEP 1: classify Sim. (which is reweighted by weights_push) to Data\n",
    "    # weights reweighted Sim. --> Data\n",
    "    print(\"\\n\\n\\n Iteration %d,  STEP 1, events that pass reco\\n\\n\\n\" % (i+1))\n",
    "    \n",
    "\n",
    "    weights_1 = np.concatenate((weights_push, w_data))\n",
    "    #QUESTION: concatenation here confuses me\n",
    "    # actual weights for Sim., ones for Data (not MC weights)\n",
    "\n",
    "    X_train_1, X_test_1, Y_train_1, Y_test_1, w_train_1, w_test_1 = train_test_split(\n",
    "        xvals_1, yvals_1, weights_1) #REMINDER: made up of synthetic+measured\n",
    "\n",
    "#    model.compile(loss='binary_crossentropy',\n",
    "#                  optimizer='Adam',\n",
    "#                  metrics=['accuracy'])\n",
    "\n",
    "    model.compile(loss='binary_crossentropy',\n",
    "                  optimizer=the_optimizer,\n",
    "                  metrics=['accuracy'],\n",
    "                  weighted_metrics=[])    \n",
    "    \n",
    "    this_hist = model.fit(X_train_1[X_train_1!=dummyval],\n",
    "              Y_train_1[X_train_1!=dummyval],\n",
    "              sample_weight=w_train_1[X_train_1!=dummyval],\n",
    "              epochs=max_epochs,\n",
    "              batch_size=batch_size_setval,\n",
    "              validation_data=(X_test_1[X_test_1!=dummyval], Y_test_1[X_test_1!=dummyval], w_test_1[X_test_1!=dummyval]),\n",
    "              callbacks=[earlystopping],\n",
    "              verbose=1)\n",
    "\n",
    "    for ei in range(0,len(this_hist.history['loss'])):\n",
    "        of_training_history[i,0,ei] = this_hist.history['loss'][ei]\n",
    "        of_training_history_val[i,0,ei] = this_hist.history['val_loss'][ei]\n",
    "    \n",
    "    \n",
    "    weights_pull = weights_push * reweight(theta0_S) \n",
    "    #QUESTION: above model used in reweight function (model.predict)?\n",
    "    #QUESTION: Model trains until synthetic is indistinguishable from data? How does this work? \n",
    "    #How are weights then iteratively multiplied?\n",
    " \n",
    "\n",
    "    ##-- owen: save NN output for each iteration, step.\n",
    "    nn_output[i,0,:] = np.squeeze(  model.predict(theta0_S, batch_size=10000) )\n",
    "\n",
    "\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "\n",
    "\n",
    "    print(\"\\n\\n\\n Iteration %d,  STEP 1, events that do NOT pass reco\\n\\n\\n\" % (i+1))\n",
    "\n",
    "    ###\n",
    "    #Need to do something with events that don't pass reco.\n",
    "    \n",
    "    #One option is to take the prior:\n",
    "    #weights_pull[theta0_S==dummyval] = 1. \n",
    "    \n",
    "    #Another option is to assign the average weight: <w|x_true>.  To do this, we need to estimate this quantity.\n",
    "    xvals_1b = np.concatenate([theta0_G[theta0_S!=dummyval],theta0_G[theta0_S!=dummyval]])\n",
    "    yvals_1b = np.concatenate([np.ones(len(theta0_G[theta0_S!=dummyval])),np.zeros(len(theta0_G[theta0_S!=dummyval]))])\n",
    "    weights_1b = np.concatenate([weights_pull[theta0_S!=dummyval],np.ones(len(theta0_G[theta0_S!=dummyval]))])\n",
    "    \n",
    "    X_train_1b, X_test_1b, Y_train_1b, Y_test_1b, w_train_1b, w_test_1b = train_test_split(\n",
    "        xvals_1b, yvals_1b, weights_1b)    \n",
    "    \n",
    "#    model.compile(loss='binary_crossentropy',\n",
    "#                  optimizer='Adam',\n",
    "#                  metrics=['accuracy'])\n",
    "    \n",
    "    model.compile(loss='binary_crossentropy',\n",
    "                  optimizer=the_optimizer,\n",
    "                  metrics=['accuracy'],\n",
    "                  weighted_metrics=[])\n",
    "    \n",
    "    \n",
    "    this_hist = model.fit(X_train_1b,\n",
    "              Y_train_1b,\n",
    "              sample_weight=w_train_1b,\n",
    "              epochs=max_epochs,\n",
    "              batch_size=batch_size_setval,\n",
    "              validation_data=(X_test_1b, Y_test_1b, w_test_1b),\n",
    "              callbacks=[earlystopping],\n",
    "              verbose=1)\n",
    "\n",
    "\n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    average_vals = reweight(theta0_G[theta0_S==dummyval])\n",
    "    weights_pull[theta0_S==dummyval] = average_vals\n",
    "    ###\n",
    "    \n",
    "    \n",
    "    ##-- owen: the syntax below is a bit confusing.\n",
    "    #          it is equivalent to weights[i,0,:] I think.  See Python-syntax-testing notebook.\n",
    "    weights[i, :1, :] = weights_pull\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    ##-----------------------------------------------------------------------\n",
    "    \n",
    "    \n",
    "    \n",
    "\n",
    "    # STEP 2: classify Gen. to reweighted Gen. (which is reweighted by weights_pull)\n",
    "    # weights Gen. --> reweighted Gen.\n",
    "    print(\"\\n\\n\\n Iteration %d,  STEP 2, events that pass reco\\n\\n\\n\" % (i+1))\n",
    "\n",
    "    #weights_2 = np.concatenate((np.ones(len(theta0_G)), weights_pull))\n",
    "    # ones for Gen. (not MC weights), actual weights for (reweighted) Gen.\n",
    "    \n",
    "    ##-- owen: this is the way it's done in the papers (I think).\n",
    "    #          At this point weights_push should still have the values from the end of the last iteration.\n",
    "    weights_2 = np.concatenate((weights_push, weights_pull))\n",
    "    \n",
    "    \n",
    "    \n",
    "\n",
    "    X_train_2, X_test_2, Y_train_2, Y_test_2, w_train_2, w_test_2 = train_test_split(\n",
    "        xvals_2, yvals_2, weights_2)\n",
    "\n",
    "#    model.compile(loss='binary_crossentropy',\n",
    "#                  optimizer='Adam',\n",
    "#                  metrics=['accuracy'])\n",
    "    \n",
    "\n",
    "    model.compile(loss='binary_crossentropy',\n",
    "                  optimizer=the_optimizer,\n",
    "                  metrics=['accuracy'],\n",
    "                  weighted_metrics=[])    \n",
    "    \n",
    "    this_hist = model.fit(X_train_2,\n",
    "              Y_train_2,\n",
    "              sample_weight=w_train_2,\n",
    "              epochs=max_epochs,\n",
    "              batch_size=batch_size_setval,\n",
    "              validation_data=(X_test_2, Y_test_2, w_test_2),\n",
    "              callbacks=[earlystopping],\n",
    "              verbose=1)\n",
    "\n",
    "    for ei in range(0,len(this_hist.history['loss'])):\n",
    "        of_training_history[i,1,ei] = this_hist.history['loss'][ei]\n",
    "        of_training_history_val[i,1,ei] = this_hist.history['val_loss'][ei]        \n",
    "    \n",
    "    \n",
    "    \n",
    "    #weights_push = reweight(theta0_G)    \n",
    "    \n",
    "    \n",
    "    #-- owen: this is the way it's done in the papers (I think)\n",
    "    weights_push = weights_push * reweight(theta0_G)    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    ##-- owen: save NN output for each iteration, step.\n",
    "    nn_output[i,1,:] = np.squeeze(  model.predict(theta0_G, batch_size=10000) )\n",
    "    \n",
    "    \n",
    "    print(\"\\n\\n\\n Iteration %d,  STEP 2, events that do NOT pass reco\\n\\n\\n\" % (i+1))\n",
    "    \n",
    "\n",
    "    ###\n",
    "    #Need to do something with events that don't pass truth    \n",
    "    \n",
    "    #One option is to take the prior:\n",
    "    #weights_push[theta0_G==dummyval] = 1. \n",
    "    \n",
    "    #Another option is to assign the average weight: <w|x_reco>.  To do this, we need to estimate this quantity.\n",
    "    xvals_1b = np.concatenate([theta0_S[theta0_G!=dummyval],theta0_S[theta0_G!=dummyval]])\n",
    "    yvals_1b = np.concatenate([np.ones(len(theta0_S[theta0_G!=dummyval])),np.zeros(len(theta0_S[theta0_G!=dummyval]))])\n",
    "    weights_1b = np.concatenate([weights_push[theta0_G!=dummyval],np.ones(len(theta0_S[theta0_G!=dummyval]))])\n",
    "    \n",
    "    X_train_1b, X_test_1b, Y_train_1b, Y_test_1b, w_train_1b, w_test_1b = train_test_split(\n",
    "        xvals_1b, yvals_1b, weights_1b)    \n",
    "    \n",
    "    \n",
    "    \n",
    "#    model.compile(loss='binary_crossentropy',\n",
    "#                  optimizer='Adam',\n",
    "#                  metrics=['accuracy'])\n",
    "    \n",
    "    model.compile(loss='binary_crossentropy',\n",
    "                  optimizer=the_optimizer,\n",
    "                  metrics=['accuracy'],\n",
    "                  weighted_metrics=[])    \n",
    "\n",
    "    \n",
    "    \n",
    "    model.fit(X_train_1b,\n",
    "              Y_train_1b,\n",
    "              sample_weight=w_train_1b,\n",
    "              epochs=max_epochs,\n",
    "              batch_size=batch_size_setval,\n",
    "              validation_data=(X_test_1b, Y_test_1b, w_test_1b),\n",
    "              callbacks=[earlystopping],\n",
    "              verbose=1)\n",
    "    \n",
    "    average_vals = reweight(theta0_S[theta0_G==dummyval])\n",
    "    weights_push[theta0_G==dummyval] = average_vals\n",
    "    ###    \n",
    "\n",
    "    \n",
    "    ##-- owen: the syntax below is a bit confusing.\n",
    "    #          it is equivalent to weights[i,1,:] I think.  See Python-syntax-testing notebook.\n",
    "    \n",
    "    weights[i, 1:2, :] = weights_push\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-17T04:28:25.400950Z",
     "start_time": "2020-11-17T04:28:20.626783Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "bins = np.linspace(-4, 4, 41)\n",
    "\n",
    "plt.figure(figsize=(12, 5))\n",
    "\n",
    "fig, ax = plt.subplots(1,\n",
    "                       2,\n",
    "                       figsize=(12, 6),\n",
    "                       constrained_layout=True,\n",
    "                       sharey=True)\n",
    "\n",
    "#Detector-level\n",
    "ax[0].set_title(\"Initialization, Detector-level\",style='italic',loc='right')\n",
    "hist0 = ax[0].hist(theta0_S[theta0_S!=dummyval],\n",
    "                 bins=bins,\n",
    "                 color=\"orange\",\n",
    "                 label=r'($\\mu$, $\\sigma$) = {}'.format(theta0_param),\n",
    "                 **plot_style_2)\n",
    "\n",
    "_,_,_= ax[0].hist(\n",
    "    theta0_S[theta0_S!=0],\n",
    "    bins=bins,\n",
    "    label='($\\mu$, $\\sigma$) = {}\\nDCTR wgt.'.format(theta0_param),\n",
    "    **plot_style_1)\n",
    "_,_,_= ax[0].hist(theta_unknown_S[theta_unknown_S!=dummyval],\n",
    "                 bins=bins,\n",
    "                 label=r'($\\mu$, $\\sigma$) = ?',\n",
    "                 weights=weights[i, 0, :][theta_unknown_S!=dummyval],\n",
    "                 **plot_style_2,\n",
    "                color=\"black\")\n",
    "ax[0].legend(frameon=False)\n",
    "ax[0].set_xlabel(r\"$x_S$\")\n",
    "ax[0].set_ylabel(\"Events per bin\")\n",
    "\n",
    "#Particle-level\n",
    "ax[1].set_title(\"Initialization, Particle-level\",style='italic',loc='right')\n",
    "_,_,_=ax[1].hist(theta0_G[theta0_G!=dummyval],\n",
    "                 bins=bins,\n",
    "                 label=r'($\\mu$, $\\sigma$) = {}'.format(theta0_param),\n",
    "                 **plot_style_2)\n",
    "\n",
    "_,_,_= ax[1].hist(\n",
    "    theta0_G[theta0_G!=0],\n",
    "    bins=bins,\n",
    "    label='($\\mu$, $\\sigma$) = {}\\nDCTR wgt.'.format(theta0_param),\n",
    "    **plot_style_1)\n",
    "_,_,_= ax[1].hist(theta_unknown_G[theta_unknown_G!=dummyval],\n",
    "                 bins=bins,\n",
    "                 label=r'($\\mu$, $\\sigma$) = ?',\n",
    "                 **plot_style_2,\n",
    "                color=\"green\")\n",
    "ax[1].legend(frameon=False)\n",
    "ax[1].set_xlabel(r\"$x_G$\")\n",
    "ax[1].set_ylabel(\"Events per bin\")\n",
    "\n",
    "plt.savefig(\"plot_0.pdf\")\n",
    "\n",
    "#Iterations\n",
    "for i in range(iterations):\n",
    "    print(\"ITERATION {}:\".format(i + 1))\n",
    "    plt.figure(figsize=(12, 5))\n",
    "    \n",
    "    fig, ax = plt.subplots(1,2,\n",
    "                       figsize=(12, 6),\n",
    "                       constrained_layout=True,\n",
    "                       sharey=True)\n",
    "    \n",
    "    #Detector-level\n",
    "    ax[0].set_title(\"Iteration \" +str(i+1)+ \", Step 1\",style='italic',loc='right')\n",
    "    _,_,_ = ax[0].hist(theta0_S[theta0_S!=dummyval],\n",
    "                     bins=bins,\n",
    "                     label=r'($\\mu$, $\\sigma$) = {}'.format(theta0_param),\n",
    "                     color=\"orange\",\n",
    "                     **plot_style_2)\n",
    "\n",
    "    _,_,_ = ax[0].hist(\n",
    "        theta0_S[theta0_S!=dummyval],\n",
    "        bins=bins,\n",
    "        label='($\\mu$, $\\sigma$) = {}\\nDCTR wgt.'.format(theta0_param),\n",
    "        weights=weights[i, 0, :][theta0_S!=dummyval],\n",
    "        **plot_style_1)\n",
    "    _,_,_ = ax[0].hist(theta_unknown_S[theta_unknown_S!=dummyval],\n",
    "                     bins=bins,\n",
    "                     label=r'($\\mu$, $\\sigma$) = ?',\n",
    "                     **plot_style_2,\n",
    "                    color=\"black\")\n",
    "    ax[0].legend(frameon=False)\n",
    "    ax[0].set_xlabel(r\"$x_S$\")\n",
    "    ax[0].set_ylabel(\"Events per bin\")\n",
    "    \n",
    "    #Particle-level\n",
    "    ax[1].set_title(\"Iteration \" +str(i+1)+ \", Step 2\",style='italic',loc='right')\n",
    "    _,_,_ = ax[1].hist(theta0_G[theta0_G!=dummyval],\n",
    "                     bins=bins,\n",
    "                     label=r'($\\mu$, $\\sigma$) = {}'.format(theta0_param),\n",
    "                     **plot_style_2)\n",
    "\n",
    "    _,_,_ = ax[1].hist(\n",
    "        theta0_G[theta0_G!=dummyval],\n",
    "        bins=bins,\n",
    "        label='($\\mu$, $\\sigma$) = {}\\nDCTR wgt.'.format(theta0_param),\n",
    "        weights=weights[i, 1, :][theta0_G!=dummyval],\n",
    "        **plot_style_1)\n",
    "    _,_,_ = ax[1].hist(theta_unknown_G[theta_unknown_G!=dummyval],\n",
    "                     bins=bins,\n",
    "                     label=r'($\\mu$, $\\sigma$) = ?',\n",
    "                     **plot_style_2,\n",
    "                    color=\"green\")\n",
    "    ax[1].legend(frameon=False)\n",
    "    ax[1].set_xlabel(r\"$x_G$\")\n",
    "    ax[1].set_ylabel(\"Events per bin\")\n",
    "    \n",
    "    plt.savefig(\"plot_\"+str(i+1)+\".pdf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Owen: inspecting a few things after running everything"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weights.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_data_and_MCback"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_data_and_MCback.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_data_and_MCback"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_data_and_MCback.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "W_data_and_MCback"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "W_data_and_MCback.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "w_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "w_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "theta_unknown_S_withback[theta_unknown_S_withback!=dummyval]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "theta_unknown_S_withback[theta_unknown_S_withback!=dummyval].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig,ax = plt.subplots(1,1,figsize=(10,10))\n",
    "\n",
    "ax.hist2d(theta_unknown_S_withback[theta_unknown_S_withback!=dummyval],\n",
    "         w_data,\n",
    "         density=True,\n",
    "         bins=200,\n",
    "         norm=mpl.colors.LogNorm())\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "fig,ax = plt.subplots(4,2,figsize=(20,40))\n",
    "\n",
    "for i in range(0,4):\n",
    "    \n",
    "    ax[i][0].plot( of_training_history[i][0][of_training_history[i][0]>0] )\n",
    "    ax[i][0].plot( of_training_history_val[i][0][of_training_history[i][0]>0] )\n",
    "    \n",
    "    ax[i][1].plot( of_training_history[i][1][of_training_history[i][1]>0] )\n",
    "    ax[i][1].plot( of_training_history_val[i][1][of_training_history[i][1]>0] )    \n",
    "    \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## distributions of weights"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Weights on full simulation to match data (step1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "fig,ax = plt.subplots(iterations,2,figsize=(20,40))\n",
    "\n",
    "for i in range(0,iterations):\n",
    "    \n",
    "    ax[i][0].hist( weights[i,0,theta0_S!=dummyval], bins=80, range=[0,1.4] )\n",
    "    \n",
    "    ax[i][1].hist2d( theta0_S[theta0_S!=dummyval], weights[i,0,theta0_S!=dummyval], \n",
    "                    bins=200, norm=mpl.colors.LogNorm(),\n",
    "                   range=([-5,5],[0,1.4]))\n",
    "    ax[i][1].grid()\n",
    "    \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Weights on gen (step2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "fig,ax = plt.subplots(iterations,2,figsize=(20,40))\n",
    "\n",
    "for i in range(0,iterations):\n",
    "    \n",
    "    ax[i][0].hist( weights[i,1,theta0_G!=dummyval], bins=80, range=[0,1.4] )\n",
    "    \n",
    "    ax[i][1].hist2d( theta0_G[theta0_G!=dummyval], weights[i,1,theta0_G!=dummyval], \n",
    "                    bins=200, norm=mpl.colors.LogNorm(),\n",
    "                   range=([-5,5],[0,1.4]))\n",
    "    ax[i][1].grid()\n",
    "    \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Change in weights on fullsim (step1) between consecutive iterations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig,ax = plt.subplots(iterations-1,2,figsize=(20,30))\n",
    "\n",
    "for i in range(0,iterations-1):\n",
    "    \n",
    "    ax[i][0].hist( weights[i+1,0,theta0_S!=dummyval]-weights[i,0,theta0_S!=dummyval], bins=80,\n",
    "                 range=[-0.5,0.5])\n",
    "    \n",
    "    ax[i][1].hist2d( theta0_S[theta0_S!=dummyval], weights[i+1,0,theta0_S!=dummyval]-weights[i,0,theta0_S!=dummyval], \n",
    "                    bins=200, norm=mpl.colors.LogNorm(),\n",
    "                   range=([-5,5],[-0.5,0.5]))\n",
    "    ax[i][1].grid()\n",
    "    \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Change in weights on gen (step2) between consecutive iterations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig,ax = plt.subplots(iterations-1,2,figsize=(20,30))\n",
    "\n",
    "for i in range(0,iterations-1):\n",
    "    \n",
    "    ax[i][0].hist( weights[i+1,1,theta0_G!=dummyval]-weights[i,1,theta0_G!=dummyval], bins=80,\n",
    "                 range=[-0.2,0.2])\n",
    "    \n",
    "    ax[i][1].hist2d( theta0_G[theta0_G!=dummyval], weights[i+1,1,theta0_G!=dummyval]-weights[i,1,theta0_G!=dummyval], \n",
    "                    bins=200, norm=mpl.colors.LogNorm(),\n",
    "                   range=([-5,5],[-0.2,0.2]))\n",
    "    ax[i][1].grid()\n",
    "    \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nn_output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Output of NN for step1: distinguish data from fullsim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "fig,ax = plt.subplots(iterations,2,figsize=(20,40))\n",
    "\n",
    "for i in range(0,iterations):\n",
    "    \n",
    "    ax[i][0].hist( nn_output[i,0,theta0_S!=dummyval], bins=80, range=[0,1] )\n",
    "    ax[i][0].grid()\n",
    "    \n",
    "    ax[i][1].hist2d( theta0_S[theta0_S!=dummyval], nn_output[i,0,theta0_S!=dummyval], \n",
    "                    bins=200, norm=mpl.colors.LogNorm(),\n",
    "                   range=([-5,5],[0,1]))\n",
    "    ax[i][1].grid()\n",
    "    \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## NN output of step2 : distinguish gen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "fig,ax = plt.subplots(iterations,2,figsize=(20,40))\n",
    "\n",
    "for i in range(0,iterations):\n",
    "    \n",
    "    ax[i][0].hist( nn_output[i,1,theta0_G!=dummyval], bins=80, range=[0,1] )\n",
    "    ax[i][0].grid()\n",
    "    \n",
    "    ax[i][1].hist2d( theta0_G[theta0_G!=dummyval], nn_output[i,1,theta0_G!=dummyval], \n",
    "                    bins=200, norm=mpl.colors.LogNorm(),\n",
    "                   range=([-5,5],[0,1]))\n",
    "    ax[i][1].grid()\n",
    "    \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "notify_time": "0",
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
